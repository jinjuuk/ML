{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b385d7d3-76b4-4af2-b903-a70d74587320",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcc3d07-b018-49b8-9d15-de0945afd436",
   "metadata": {},
   "source": [
    "# ML공부"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c335d45a-4578-4a59-9573-2851987d70de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width\n",
       "0            5.1          3.5           1.4          0.2\n",
       "1            4.9          3.0           1.4          0.2\n",
       "2            4.7          3.2           1.3          0.2\n",
       "3            4.6          3.1           1.5          0.2\n",
       "4            5.0          3.6           1.4          0.2\n",
       "..           ...          ...           ...          ...\n",
       "95           5.7          3.0           4.2          1.2\n",
       "96           5.7          2.9           4.2          1.3\n",
       "97           6.2          2.9           4.3          1.3\n",
       "98           5.1          2.5           3.0          1.1\n",
       "99           5.7          2.8           4.1          1.3\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pj_ds_functions import y_lable_encoding\n",
    "df = sns.load_dataset('iris')\n",
    "#df.head()\n",
    "df = df.query(\"species != 'virginica'\")\n",
    "\n",
    "y = df['species']\n",
    "X = df.drop(columns='species', axis=1)\n",
    "y = y_lable_encoding(y)\n",
    "print(y)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2c60a3-145f-4389-b8c8-ac836e19b19f",
   "metadata": {},
   "source": [
    "## 학습/테스트 데이터 세트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a98255-c295-49a7-9517-fcde98c80845",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size= 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66efdf54-8d67-4da9-b07b-275e72940fbf",
   "metadata": {},
   "source": [
    "## 정규화, 표준화\n",
    "학습/데스트 데이버 세트로 분리하기전에 먼저 전체 데이터 세트에 스케일링을 적용한뒤 학습과 테스트 데이터 세트로 분리하는 것이 더 바람직합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b133136-f158-46f5-918d-0e21badad16d",
   "metadata": {},
   "source": [
    "### 정규화\n",
    "* 정규화 정의: 데이터의 스케일을 특정 범위, 보통 0과 1 사이로 조정하는 과정입니다.\n",
    "* 목적: 서로 다른 스케일을 가진 데이터 특성들을 동일한 범위로 조정하여, 모델 학습의 일관성과 안정성을 높이기 위함입니다.\n",
    "* 중요성: 모든 데이터 포인트가 동일한 스케일을 갖도록 하여, 특정 특성이 모델 학습에 지나치게 큰 영향을 미치는 것을 방지합니다.\n",
    "* 적용 분야: 신경망, 거리 기반 알고리즘(예: k-최근접 이웃) 등 스케일의 영향을 받는 다양한 머신러닝 알고리즘에 적용됩니다.\n",
    "* 결과: 데이터의 최소값이 0, 최대값이 1이 되며, 모든 특성 값들이 이 범위 내로 조정되어 모델의 훈련이 용이해집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e065a29b-308f-41d1-8b5a-a11e3b87a328",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmScaler = MinMaxScaler()\n",
    "mmScaler = mmScaler.fit(X_train)\n",
    "mmScaler = mmScaler.transform(X_train)\n",
    "#mmScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c08b14a-a69e-44ac-b646-e7b3278e8a13",
   "metadata": {},
   "source": [
    "### 표준화\n",
    "\n",
    "* 표준화 정의: 데이터에서 각 값에서 평균을 빼고, 그 결과를 표준편차로 나누는 과정입니다.\n",
    "* 목적: 데이터의 특성들이 다른 스케일을 가질 때, 이를 표준 정규 분포(평균 0, 표준편차 1)에 근사하도록 변환하여 모델의 학습 효율성을 높이고 성능을 개선하기 위함입니다.\n",
    "* 중요성: 서로 다른 단위 또는 스케일을 가진 데이터를 비교, 분석하기 용이하게 만들고, 여러 머신러닝 알고리즘에서 더 나은 성능을 얻기 위해 필수적입니다.\n",
    "* 적용 분야: 대부분의 머신러닝 알고리즘, 특히 거리 기반 알고리즘(예: k-최근접 이웃, SVM) 및 선형 모델(예: 선형 회귀, 로지스틱 회귀)에 유용합니다.\n",
    "* 결과: 데이터의 모든 특성이 동일한 스케일을 갖게 되어, 모델 학습이 더욱 효과적이고 공정한 비교가 가능해집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e823c0c9-a44d-4deb-b2e9-91c3d1ea40f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "SScaler = StandardScaler()\n",
    "SScaler = SScaler.fit(X_train)\n",
    "SScaler = SScaler.transform(X_train)\n",
    "#SScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd1e6b1-5610-463e-808a-b3f459ece0b0",
   "metadata": {},
   "source": [
    "## 평가\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* F1-score(trade-off) -> Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f03ea07-509e-4362-8de3-854c95da5372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 준비\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "ds_model = DecisionTreeClassifier()\n",
    "ds_model = ds_model.fit(X_train, y_train)\n",
    "yhat = ds_model.predict(X_test)\n",
    "yhat_proba = ds_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1487a2-4976-448a-8079-9b1a5400df1b",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b03710e0-7f82-4abd-ac5a-794cffc70a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1]\n",
      "[0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(y_test)\n",
    "print(yhat)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2bee43-2d79-4660-9f75-12293d385e6c",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "981f74de-f498-4253-beeb-1f6116779a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0],\n",
       "       [ 0,  9]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b224bf3-818d-4714-b15e-bd553cea745f",
   "metadata": {},
   "source": [
    "### F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f82ce349-1b6a-46de-8e3c-631bc5290756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1]\n",
      "[0 1 0 1 0 0 0 1 0 0 0 1 0 1 1 1 0 0 1 1]\n",
      "precision score:  1.0\n",
      "recall score:  1.0\n",
      "F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "print(y_test)\n",
    "print(yhat)\n",
    "f1_score = f1_score(y_test, yhat)\n",
    "pre_score = precision_score(y_test, yhat)\n",
    "rec_score = recall_score(y_test, yhat)\n",
    "\n",
    "print(\"precision score: \", pre_score)\n",
    "print(\"recall score: \", rec_score)\n",
    "print(\"F1 Score: \", f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83edf6a0-74c8-4c6d-b6c7-103b6f3dc85d",
   "metadata": {},
   "source": [
    "### ROC_AUC Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10b2f162-abd6-414f-835a-c11ddac5c0bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = yhat_proba[:,[1]]\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic Example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade4fd63-6c46-49d6-83ec-a1050cc40558",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222e84df-e98b-4d15-860b-1bec901fb7a8",
   "metadata": {},
   "source": [
    "### Stratified K-fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca94184f-11be-48bd-9c82-0323173120d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV=2 교차 검증 f1: 1.0\n",
      "CV=3 교차 검증 f1: 1.0\n",
      "CV=4 교차 검증 f1: 1.0\n",
      "CV=5 교차 검증 f1: 1.0\n",
      "CV=6 교차 검증 f1: 1.0\n",
      "CV=7 교차 검증 f1: 1.0\n",
      "CV=8 교차 검증 f1: 1.0\n",
      "CV=9 교차 검증 f1: 1.0\n",
      "CV=10 교차 검증 f1: 1.0\n"
     ]
    }
   ],
   "source": [
    "#모델 준비\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "for i in range(2,11):\n",
    "    cross_score = cross_val_score(ds_model, X_train, y_train,scoring='f1',cv=i)\n",
    "    print(f'CV={i} 교차 검증 f1: {np.mean(cross_score)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e139ff-0f46-415c-ac05-09b98b8377fe",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc8b9942-623d-4b56-89e9-6fcf0bb25b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'min_samples_split': 2}\n",
      "0.9250000000000002\n",
      "DecisionTreeClassifier(max_depth=2)\n",
      "Species\n",
      "True     28\n",
      "False     2\n",
      "Name: count, dtype: int64\n",
      "[0. 0. 1. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydataset\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "iris = pydataset.data('iris')\n",
    "iris.head()\n",
    "\n",
    "X = iris.iloc[:,:-1]\n",
    "y = iris['Species']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "#print('X학습 행 갯수: ',X_train.shape[0])\n",
    "#print('X테스트 행 갯수: ',X_test.shape[0])\n",
    "#print('y학습 행 갯수: ',y_train.shape[0])\n",
    "#print('y테스트 행 갯수: ',y_test.shape[0])\n",
    "\n",
    "#모델 설정, 그리드 서치를 위한 dt 모델 파라미터 설정\n",
    "dt = DecisionTreeClassifier()\n",
    "parameters = {'max_depth':[1,2,3], 'min_samples_split':[2,3]}\n",
    "\n",
    "# 그리드서치 설정\n",
    "grid_dt = GridSearchCV(dt, param_grid=parameters, cv=3,refit=True, n_jobs=-1) \n",
    "#refit: 가장 좋은 파라미터 설정으로 재학습시킴, n_jobs: 병열으로 실행(3이면 3가지일을 동시에 함, cpu의 논리 프로세서가 max 값임, -1은 코어 전부 다씀)\n",
    "\n",
    "grid_dt.fit(X_train, y_train) #학습\n",
    "\n",
    "print(grid_dt.best_params_) #최고의 파라미터 확인\n",
    "\n",
    "print(grid_dt.best_score_) #최고의 정확도 확인\n",
    "\n",
    "#최고의 파라미터로 훈련된 모델 객채가 저장되어있음, **fit할 필요없음**\n",
    "print(grid_dt.best_estimator_) #최고의 파라미터가 저장된 모델의 객체\n",
    "\n",
    "dt_best = grid_dt.best_estimator_\n",
    "yhat = dt_best.predict(X_test)\n",
    "yhat\n",
    "\n",
    "y_test == yhat\n",
    "\n",
    "print((y_test == yhat).value_counts()) #실제값과 예측값 확인\n",
    "print(dt_best.feature_importances_) # 피쳐의 중요도 확인\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, yhat) #테스트 값의 정확도 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91c8abaa-90e5-446a-8cf7-c5b8f6c5a7ca",
   "metadata": {},
   "source": [
    "# Hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50deefcb-5970-46eb-a3ed-9f253ca4f767",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install hyperopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d3821391-70ec-4fc8-814e-353e902c690a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "333648ed-33fa-4eda-a10d-dcad8b83658f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': <hyperopt.pyll.base.Apply at 0x1ee7b9a6770>,\n",
       " 'y': <hyperopt.pyll.base.Apply at 0x1ee7b9a5630>}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#입력값의 검색 공간을 제공하는 대표적 함수\n",
    "#-10~10까지 1간격을 가지는 입력 변수 x와 -15_15까지 1간격으로 입력 변수 y 설정\n",
    "search_space = {'x': hp.quniform('x',-10,10,1), 'y': hp.quniform('y', -15,15,1)}\n",
    "search_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da22864d-048a-4a3e-875c-9a5691ac73c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-10,  -9,  -8,  -7,  -6,  -5,  -4,  -3,  -2,  -1,   0,   1,   2,\n",
       "         3,   4,   5,   6,   7,   8,   9])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#위와 같은 방법을 numpy로 구현해본것\n",
    "import numpy as np\n",
    "np.linspace(-10,10,100)\n",
    "np.arange(-10,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e885fd27-7ca2-4cb3-badc-ee39a1ac757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import STATUS_OK\n",
    "#목적 함수를 생성. 변수값과 변수 검색 공간을 가지는 딕셔너리를 인자로 받고, 특정값을 반환\n",
    "def objective_func(search_space):\n",
    "    x = search_space['x']\n",
    "    y = search_space['y']\n",
    "    retval = x**2 - 20*y\n",
    "    return retval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d327c4a1-798d-44b2-b329-a0ba92211b75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 5/5 [00:00<?, ?trial/s, best loss: -224.0]\n",
      "best: {'x': -4.0, 'y': 12.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "#입력 결과값을 저장한 Trials 객체값 생성\n",
    "trial_val = Trials()\n",
    "\n",
    "#목적 함수의 최솟값을 반환하는 최적 입력 변수값을 5번의 입력값 시도(max_evals=5)로 찾아냄\n",
    "best_01 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=5,\n",
    "              trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best:', best_01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcb23bdf-c0e6-4535-96db-8ec7b08aeb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 20/20 [00:00<00:00, 1109.38trial/s, best loss: -296.0]\n",
      "best_02: {'x': 2.0, 'y': 15.0}\n"
     ]
    }
   ],
   "source": [
    "trial_val = Trials()\n",
    "#max_evals를 20회로 늘려서 재테스트\n",
    "best_02 = fmin(fn=objective_func, space=search_space, algo=tpe.suggest, max_evals=20,\n",
    "              trials=trial_val, rstate=np.random.default_rng(seed=0))\n",
    "print('best_02:', best_02)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d61baf-b04e-4247-aaaf-103d93414710",
   "metadata": {},
   "source": [
    "### Hyperopt 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4caa0ce-a432-4571-9896-273ec1861079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a121c90-0889-4488-8562-679f3e9ef2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def breast_cancer():\n",
    "    cancer = load_breast_cancer()\n",
    "    X = cancer['data']\n",
    "    y = cancer['target']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=156)\n",
    "    print(X_train.shape)\n",
    "    print(y_train.shape)\n",
    "    print(X_test.shape)\n",
    "    print(y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b6e87d0d-0e3c-48b3-9054-f769a7bf8fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30)\n",
      "(455,)\n",
      "(114, 30)\n",
      "(114,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2421a88a-93a4-4511-8daa-e4357a3a6dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=156)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64a0ac93-9147-412a-aff8-991404525caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "#찾을 범위 설정\n",
    "#max_depth는 5에서 1 사이까지 간격으로, min_child_weight는 1에서 2 까지 1 간격으로\n",
    "# colsample_bytree는 0.5에서 1사이, learning_rate는 0.01에서 0.2 사이 정규 분포된 값으로 검색\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                   } \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ec0bfc6-13f9-407f-9c60-0d69ad6ec580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#fmin()에서 입력된 search_space 값으로 입력된 모든 값은 실수형임\n",
    "#XGBClassifier의 정수형 하이퍼 파라미터는 정수형 변환을 해줘야함\n",
    "#정확도는 높을수록 더 좋은 수치임. -1* 정확도를 곱해서 큰 정확도 값일수록 최소가 되도록 변환\n",
    "def objective_func(search_space):\n",
    "    #수행 시간 절약을 위해 n_estimator=100으러 축소\n",
    "    xgb_clf = XGBClassifier(n_estimators=100, max_depth=int(search_space['max_depth']),\n",
    "                                min_child_weight=int(search_space['min_child_weight']),\n",
    "                                learning_rate=search_space['learning_rate'],\n",
    "                                colsample_bytree=search_space['colsample_bytree'],\n",
    "                                eval_metric='logloss')\n",
    "    accuracy = np.mean(cross_val_score(xgb_clf, X_train, y_train, scoring='accuracy', cv=3))\n",
    "    #\n",
    "    return -1*accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f34bc94b-3f7a-4e63-a58c-a8c5c6db022d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from hyperopt import fmin, tpe, Trials\n",
    "#입력 결과값을 저장한 Trials 객체값 생성\n",
    "#trial_val = Trials()\n",
    "\n",
    "#목적 함수의 최솟값을 반환하는 최적 입력 변수값을 5번의 입력값 시도(max_evals=5)로 찾아냄\n",
    "#best = fmin(fn=objective_func, space=xgb_search_space, algo=tpe.suggest, max_evals=50,\n",
    "#              trials=trial_val, rstate=np.random.default_rng(seed=9))\n",
    "\n",
    "#print('best:', best)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1de0a8-8cba-4046-8ebb-53dc609aa7b6",
   "metadata": {},
   "source": [
    "# 결정나무 Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb8e1216-1169-4c13-bbc6-2799680bcdf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6592592592592592"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydataset\n",
    "dia =pydataset.data('diamonds')\n",
    "dia = dia.sample(frac=.1)\n",
    "dia.columns\n",
    "\n",
    "X = dia[['depth', 'table', 'price', 'x', 'y','z']]\n",
    "y = dia[['cut']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.1, random_state=1234)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "dt_clf.fit(X_train, y_train)\n",
    "yhat = dt_clf.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af107239-d4dc-4e7f-bb1c-4eccd83e2638",
   "metadata": {},
   "source": [
    "### 교차검증을 통하여 정확도를 높여봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8191451e-b66a-47b1-88cb-184e65fd05cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross_val for each:  [0.6429366  0.6407119  0.66295884]\n",
      "mean_cross_val 0.6488691138301818\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(dt_clf, X, y, scoring='accuracy', cv=3)\n",
    "print('cross_val for each: ', scores)\n",
    "print('mean_cross_val', np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43718e5f-3825-4039-893f-025345b6d35d",
   "metadata": {},
   "source": [
    "### GridSearchCV로 정확도 높이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4be9344-91b9-4762-adbe-9c29184e074a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier(max_depth=6, min_samples_split=7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7092592592592593"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_param = {'max_depth': [2,4,6,8,10,12,14,16,18,20,22,24], 'min_samples_split':[2,3,4,5,6,7,8,9,10]}\n",
    "grid_dt2 = GridSearchCV(dt_clf, param_grid=grid_param, cv=10, refit=True, n_jobs=-1)\n",
    "grid_dt2.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "grid_dt2.best_params_\n",
    "\n",
    "grid_dt2.best_score_\n",
    "print(grid_dt2.best_estimator_)\n",
    "best_esti = grid_dt2.best_estimator_\n",
    "\n",
    "yhat = best_esti.predict(X_test)\n",
    "yhat\n",
    "\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e74cd-93b3-4e52-89ed-85f066078a29",
   "metadata": {},
   "source": [
    "# 앙상블 학습 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bdeb55c-1aac-42f4-adb2-d307d7fe3e17",
   "metadata": {},
   "source": [
    "## RandomForstClassifier + GridSearchCV사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9756efd9-391f-418f-87e2-e2d0fe75ddd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\base.py:1351: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(max_depth=22, min_samples_split=6, n_estimators=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7185185185185186"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_clf = RandomForestClassifier()\n",
    "grid_param2 = {'n_estimators': [10,50,100],'max_depth': [2,4,6,8,10,12,14,16,18,20,22,24], 'min_samples_split':[2,4,6,8,10,12,14,16,18,20]}\n",
    "grid_dt3 = GridSearchCV(rf_clf, param_grid=grid_param2, cv=5, refit=True, n_jobs=-1)\n",
    "grid_dt3.fit(X_train, y_train)\n",
    "\n",
    "grid_dt3.best_params_\n",
    "\n",
    "grid_dt3.best_score_\n",
    "print(grid_dt3.best_estimator_)\n",
    "best_esti = grid_dt3.best_estimator_\n",
    "\n",
    "yhat = best_esti.predict(X_test)\n",
    "yhat\n",
    "\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f302bb40-e1d0-424f-89fe-650546b3aac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25065472, 0.30812448, 0.11480294, 0.11846255, 0.10888206,\n",
       "       0.09907325])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_esti.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7cf9b42-de28-43f0-9c1c-995f82475b02",
   "metadata": {},
   "source": [
    "## XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aeb3de73-62a4-4714-83c2-2af02074d2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7018518518518518"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y=encoder.transform(y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=.1, random_state=1234)\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=40, learning_rate=0.05, max_depth=3, eval_metric='logloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "yhat = xgb.predict(X_test)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79466ec-c5b0-4b77-8ba3-7affe485d505",
   "metadata": {},
   "source": [
    "## LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "44751a4d-705a-482c-ab27-b584ce95c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c8226e1-4bf0-4a16-83a1-9adc2c19abae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Unknown parameter: eval_metric\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6166666666666667"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "lgmb = LGBMClassifier(n_estimators=5, learning_rate=0.05, max_depth=3, eval_metric='logloss')\n",
    "lgmb.fit(X_train, y_train)\n",
    "yhat = lgmb.predict(X_test)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5479b3d4-2acf-401a-9f51-c2a574eb657d",
   "metadata": {},
   "source": [
    "# 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb0c7d6-e218-49e1-93e1-dcd41911fbe5",
   "metadata": {},
   "source": [
    "## 1. 예시 타이타닉 데이터\n",
    "1. 필요한 칼럼을 뽑아낸다 (X,y)\n",
    "2. 결측치를 처리한다\n",
    "3. 이상치를 처리한다\n",
    "4. 스케일링한다\n",
    "5. 적용한 모델을 선택한다 -> fit -> predict -> 평가\n",
    "6. 5번을 파라미터를 바꾸어가면서 반복한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6401e6b-050c-4ed9-9bd9-b69f9cb74007",
   "metadata": {},
   "source": [
    "## 2. 예시 Iris + Decision Tree + graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4c584674-c325-4daf-a685-8793ea4107ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e112a8a7-dbf9-4d0d-a360-ca813981ae43",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2f3a6dd-5487-4f30-8f5b-99dd71e14447",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90078d26-fe8d-4e1c-8a20-13f882a92cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.4 , stratify=y, random_state=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2d57cc56-2d4f-406b-8199-f3a444114283",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf = DecisionTreeClassifier(random_state=156, min_samples_leaf=1, min_samples_split=2, max_depth=2)\n",
    "dt_clf = dt_clf.fit(X_train,y_train)\n",
    "\n",
    "yhat = dt_clf.predict(X_test)\n",
    "accuracy_score(y_test, yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0478c58-f932-4571-bda8-6248fd8bbe10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 2, 2, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 2,\n",
       "       1, 1, 0, 0, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2dd2dc26-cf68-4712-8d80-dd357c0bb413",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 2, 0, 1, 1, 0, 1, 2, 2, 1, 1, 2, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 2, 2, 2, 0, 2, 2, 0, 2, 2, 2, 0, 0, 1, 1, 1, 2, 1, 1, 2, 2,\n",
       "       2, 1, 0, 0, 1, 0, 2, 2, 0, 1, 1, 2, 0, 1, 1, 2])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11026966-570d-4171-8c2f-40a03e313862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bae263d2-5698-4ba1-bd8a-1512adf71a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(dt_clf, out_file='tree.dot', class_names=iris['target_names'], \\\n",
    "               feature_names=iris['feature_names'], impurity=True, filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a0864e36-1b8f-469f-94c3-2a94991f0f0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 10.0.1 (20240210.2158)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"360pt\" height=\"335pt\"\n",
       " viewBox=\"0.00 0.00 360.25 335.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 331)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-331 356.25,-331 356.25,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"223.75,-327 58.5,-327 58.5,-236.5 223.75,-236.5 223.75,-327\"/>\n",
       "<text text-anchor=\"middle\" x=\"141.12\" y=\"-309.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal length (cm) &lt;= 2.5</text>\n",
       "<text text-anchor=\"middle\" x=\"141.12\" y=\"-293.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.667</text>\n",
       "<text text-anchor=\"middle\" x=\"141.12\" y=\"-276.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 90</text>\n",
       "<text text-anchor=\"middle\" x=\"141.12\" y=\"-260.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 30, 30]</text>\n",
       "<text text-anchor=\"middle\" x=\"141.12\" y=\"-243.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<polygon fill=\"#e58139\" stroke=\"black\" points=\"120.25,-192.25 0,-192.25 0,-118.25 120.25,-118.25 120.25,-192.25\"/>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-174.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.0</text>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-158.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 30</text>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-141.95\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 0, 0]</text>\n",
       "<text text-anchor=\"middle\" x=\"60.12\" y=\"-125.45\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = setosa</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M112.11,-236.15C104.88,-225.04 97.11,-213.1 89.85,-201.93\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"92.83,-200.1 84.44,-193.62 86.96,-203.92 92.83,-200.1\"/>\n",
       "<text text-anchor=\"middle\" x=\"78.44\" y=\"-211.76\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<polygon fill=\"#ffffff\" stroke=\"black\" points=\"305.88,-200.5 138.38,-200.5 138.38,-110 305.88,-110 305.88,-200.5\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.12\" y=\"-183.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">petal width (cm) &lt;= 1.75</text>\n",
       "<text text-anchor=\"middle\" x=\"222.12\" y=\"-166.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"middle\" x=\"222.12\" y=\"-150.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 60</text>\n",
       "<text text-anchor=\"middle\" x=\"222.12\" y=\"-133.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 30, 30]</text>\n",
       "<text text-anchor=\"middle\" x=\"222.12\" y=\"-117.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M170.14,-236.15C175.55,-227.84 181.26,-219.07 186.83,-210.5\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"189.7,-212.51 192.22,-202.22 183.83,-208.69 189.7,-212.51\"/>\n",
       "<text text-anchor=\"middle\" x=\"198.22\" y=\"-220.36\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<polygon fill=\"#4de88e\" stroke=\"black\" points=\"214.25,-74 88,-74 88,0 214.25,0 214.25,-74\"/>\n",
       "<text text-anchor=\"middle\" x=\"151.12\" y=\"-56.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.17</text>\n",
       "<text text-anchor=\"middle\" x=\"151.12\" y=\"-40.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 32</text>\n",
       "<text text-anchor=\"middle\" x=\"151.12\" y=\"-23.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 29, 3]</text>\n",
       "<text text-anchor=\"middle\" x=\"151.12\" y=\"-7.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = versicolor</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M194.88,-109.64C189.76,-101.26 184.4,-92.49 179.26,-84.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"182.34,-82.4 174.14,-75.69 176.37,-86.04 182.34,-82.4\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<polygon fill=\"#8640e6\" stroke=\"black\" points=\"352.25,-74 232,-74 232,0 352.25,0 352.25,-74\"/>\n",
       "<text text-anchor=\"middle\" x=\"292.12\" y=\"-56.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.069</text>\n",
       "<text text-anchor=\"middle\" x=\"292.12\" y=\"-40.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 28</text>\n",
       "<text text-anchor=\"middle\" x=\"292.12\" y=\"-23.7\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [0, 1, 27]</text>\n",
       "<text text-anchor=\"middle\" x=\"292.12\" y=\"-7.2\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">class = virginica</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M248.99,-109.64C254.03,-101.26 259.31,-92.49 264.38,-84.07\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"267.27,-86.06 269.43,-75.69 261.27,-82.45 267.27,-86.06\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source at 0x1ee7bb87c40>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "\n",
    "with open('tree.dot') as f:\n",
    "    dot_graph = f.read()\n",
    "\n",
    "graphviz.Source(dot_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72efc5e2-a6c4-4a5a-9538-baf520799f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.56997455, 0.43002545])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f51344e-c234-48f8-9efd-42ab07229099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4994841b-0d32-489d-93d6-67ae72dc6c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7fbd6aaf-014f-48f8-b128-caca6889af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris['data']\n",
    "y = iris['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ab821971-57e8-4c8a-8043-afdba57d5e9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>4.3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "116                4.3               3.0                1.1               0.1   \n",
       "17                 5.0               3.2                1.2               0.2   \n",
       "83                 5.8               4.0                1.2               0.2   \n",
       "25                 4.4               3.2                1.3               0.2   \n",
       "58                 4.4               3.0                1.3               0.2   \n",
       "8                  5.5               3.5                1.3               0.2   \n",
       "78                 5.0               3.5                1.3               0.3   \n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "45                 5.5               4.2                1.4               0.2   \n",
       "51                 4.6               3.2                1.4               0.2   \n",
       "56                 5.1               3.5                1.4               0.3   \n",
       "34                 5.0               3.6                1.4               0.2   \n",
       "69                 4.9               3.0                1.4               0.2   \n",
       "67                 4.4               2.9                1.4               0.2   \n",
       "33                 5.2               3.4                1.4               0.2   \n",
       "109                4.8               3.0                1.4               0.3   \n",
       "3                  5.0               3.3                1.4               0.2   \n",
       "103                4.9               3.6                1.4               0.1   \n",
       "12                 4.6               3.4                1.4               0.3   \n",
       "28                 5.1               3.7                1.5               0.4   \n",
       "35                 5.4               3.4                1.5               0.4   \n",
       "37                 5.1               3.4                1.5               0.2   \n",
       "106                4.9               3.1                1.5               0.2   \n",
       "68                 4.6               3.1                1.5               0.2   \n",
       "91                 5.2               3.5                1.5               0.2   \n",
       "60                 5.1               3.8                1.5               0.3   \n",
       "87                 5.4               3.7                1.5               0.2   \n",
       "62                 5.2               4.1                1.5               0.1   \n",
       "82                 5.0               3.4                1.5               0.2   \n",
       "53                 5.3               3.7                1.5               0.2   \n",
       "55                 5.0               3.5                1.6               0.6   \n",
       "59                 5.0               3.0                1.6               0.2   \n",
       "29                 5.0               3.4                1.6               0.4   \n",
       "4                  4.7               3.2                1.6               0.2   \n",
       "19                 5.1               3.8                1.6               0.2   \n",
       "75                 5.4               3.9                1.7               0.4   \n",
       "26                 5.4               3.4                1.7               0.2   \n",
       "92                 5.1               3.3                1.7               0.5   \n",
       "54                 5.7               3.8                1.7               0.3   \n",
       "112                4.8               3.4                1.9               0.2   \n",
       "84                 5.1               3.8                1.9               0.4   \n",
       "15                 5.1               2.5                3.0               1.1   \n",
       "86                 4.9               2.4                3.3               1.0   \n",
       "42                 5.0               2.3                3.3               1.0   \n",
       "94                 5.7               2.6                3.5               1.0   \n",
       "10                 5.0               2.0                3.5               1.0   \n",
       "96                 5.6               2.9                3.6               1.3   \n",
       "117                5.5               2.4                3.7               1.0   \n",
       "119                5.5               2.4                3.8               1.1   \n",
       "70                 5.2               2.7                3.9               1.4   \n",
       "\n",
       "     target  \n",
       "116       0  \n",
       "17        0  \n",
       "83        0  \n",
       "25        0  \n",
       "58        0  \n",
       "8         0  \n",
       "78        0  \n",
       "0         0  \n",
       "45        0  \n",
       "51        0  \n",
       "56        0  \n",
       "34        0  \n",
       "69        0  \n",
       "67        0  \n",
       "33        0  \n",
       "109       0  \n",
       "3         0  \n",
       "103       0  \n",
       "12        0  \n",
       "28        0  \n",
       "35        0  \n",
       "37        0  \n",
       "106       0  \n",
       "68        0  \n",
       "91        0  \n",
       "60        0  \n",
       "87        0  \n",
       "62        0  \n",
       "82        0  \n",
       "53        0  \n",
       "55        0  \n",
       "59        0  \n",
       "29        0  \n",
       "4         0  \n",
       "19        0  \n",
       "75        0  \n",
       "26        0  \n",
       "92        0  \n",
       "54        0  \n",
       "112       0  \n",
       "84        0  \n",
       "15        1  \n",
       "86        1  \n",
       "42        1  \n",
       "94        1  \n",
       "10        1  \n",
       "96        1  \n",
       "117       1  \n",
       "119       1  \n",
       "70        1  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df = pd.DataFrame(X_train, columns=iris['feature_names'])\n",
    "x_df['target'] = y_train\n",
    "x_df1 = x_df.sort_values(by='petal length (cm)')\n",
    "x_df1.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "40fa6434-25ff-449e-a02b-8d75e0348868",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.9</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>7.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>6.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.5</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>6.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.7</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>6.6</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "45                 5.0               2.0                3.5               1.0   \n",
       "69                 6.2               2.2                4.5               1.5   \n",
       "64                 6.3               2.3                4.4               1.3   \n",
       "51                 5.5               2.3                4.0               1.3   \n",
       "43                 5.0               2.3                3.3               1.0   \n",
       "42                 4.9               2.4                3.3               1.0   \n",
       "48                 5.5               2.4                3.8               1.1   \n",
       "47                 5.5               2.4                3.7               1.0   \n",
       "86                 6.3               2.5                5.0               1.9   \n",
       "67                 4.9               2.5                4.5               1.7   \n",
       "41                 5.1               2.5                3.0               1.1   \n",
       "82                 6.3               2.5                4.9               1.5   \n",
       "106                6.7               2.5                5.8               1.8   \n",
       "53                 5.5               2.5                4.0               1.3   \n",
       "96                 6.1               2.6                5.6               1.4   \n",
       "65                 5.5               2.6                4.4               1.2   \n",
       "54                 5.8               2.6                4.0               1.2   \n",
       "44                 5.7               2.6                3.5               1.0   \n",
       "119                7.7               2.6                6.9               2.3   \n",
       "49                 5.2               2.7                3.9               1.4   \n",
       "50                 5.8               2.7                3.9               1.2   \n",
       "55                 5.8               2.7                4.1               1.0   \n",
       "58                 5.6               2.7                4.2               1.3   \n",
       "83                 6.3               2.7                4.9               1.8   \n",
       "88                 5.8               2.7                5.1               1.9   \n",
       "87                 6.0               2.7                5.1               1.6   \n",
       "84                 5.6               2.8                4.9               2.0   \n",
       "56                 5.7               2.8                4.1               1.3   \n",
       "117                7.7               2.8                6.7               2.0   \n",
       "52                 6.1               2.8                4.0               1.3   \n",
       "111                7.4               2.8                6.1               1.9   \n",
       "100                6.4               2.8                5.6               2.1   \n",
       "98                 6.4               2.8                5.6               2.2   \n",
       "90                 5.8               2.8                5.1               2.4   \n",
       "72                 6.5               2.8                4.6               1.5   \n",
       "79                 6.2               2.8                4.8               1.8   \n",
       "76                 6.8               2.8                4.8               1.4   \n",
       "68                 5.7               2.8                4.5               1.3   \n",
       "75                 6.1               2.8                4.7               1.2   \n",
       "66                 6.0               2.9                4.5               1.5   \n",
       "114                7.3               2.9                6.3               1.8   \n",
       "60                 5.7               2.9                4.2               1.3   \n",
       "13                 4.4               2.9                1.4               0.2   \n",
       "46                 5.6               2.9                3.6               1.3   \n",
       "71                 6.6               2.9                4.6               1.3   \n",
       "62                 6.2               2.9                4.3               1.3   \n",
       "63                 6.4               2.9                4.3               1.3   \n",
       "91                 6.5               3.0                5.2               2.0   \n",
       "104                7.2               3.0                5.8               1.6   \n",
       "105                6.5               3.0                5.8               2.2   \n",
       "\n",
       "     target  \n",
       "45        1  \n",
       "69        1  \n",
       "64        1  \n",
       "51        1  \n",
       "43        1  \n",
       "42        1  \n",
       "48        1  \n",
       "47        1  \n",
       "86        2  \n",
       "67        2  \n",
       "41        1  \n",
       "82        1  \n",
       "106       2  \n",
       "53        1  \n",
       "96        2  \n",
       "65        1  \n",
       "54        1  \n",
       "44        1  \n",
       "119       2  \n",
       "49        1  \n",
       "50        1  \n",
       "55        1  \n",
       "58        1  \n",
       "83        2  \n",
       "88        2  \n",
       "87        1  \n",
       "84        2  \n",
       "56        1  \n",
       "117       2  \n",
       "52        1  \n",
       "111       2  \n",
       "100       2  \n",
       "98        2  \n",
       "90        2  \n",
       "72        1  \n",
       "79        2  \n",
       "76        1  \n",
       "68        1  \n",
       "75        1  \n",
       "66        1  \n",
       "114       2  \n",
       "60        1  \n",
       "13        0  \n",
       "46        1  \n",
       "71        1  \n",
       "62        1  \n",
       "63        1  \n",
       "91        2  \n",
       "104       2  \n",
       "105       2  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_df1 = x_df1.reset_index(drop=True)\n",
    "x_df1.head(50)\n",
    "x_df1 = x_df1.sort_values(by='sepal width (cm)')\n",
    "x_df1.head(50)\n",
    "# x_df1 = x_df1.iloc[:, ]\n",
    "# x_df1\n",
    "# a = x_df1.sort_values(by='petal width (cm)')\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95d7d5b4-2103-47cf-a834-62508c59ec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c5adba-c2ac-42c6-beca-b08b747e3edf",
   "metadata": {},
   "source": [
    "# 복습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9279eacd-4d71-4fac-b749-2c87a0c0d8b3",
   "metadata": {},
   "source": [
    "## 데이터 셋트 종류 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "380fc4d3-2a46-4436-b1ee-7f8f41fbc887",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 시본에서의 데이터셋트\n",
    "#import seaborn as sns \n",
    "#sns.get_dataset_names()\n",
    "#df = sns.load_dataset('titanic')\n",
    "\n",
    "\n",
    "## sklearn에서의 데이터 셋트\n",
    "#from sklearn.datasets import load_****\n",
    "\n",
    "##!pip install pydataset #파이데이터 셋트\n",
    "#import pydataset\n",
    "#pydataset.data()\n",
    "#pydataset.data('iris')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2f52126c-9f4f-4a7c-b709-3a2bed9bd4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>price</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.5</td>\n",
       "      <td>55.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.95</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.21</td>\n",
       "      <td>Premium</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>61.0</td>\n",
       "      <td>326</td>\n",
       "      <td>3.89</td>\n",
       "      <td>3.84</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.23</td>\n",
       "      <td>Good</td>\n",
       "      <td>E</td>\n",
       "      <td>VS1</td>\n",
       "      <td>56.9</td>\n",
       "      <td>65.0</td>\n",
       "      <td>327</td>\n",
       "      <td>4.05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>2.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.29</td>\n",
       "      <td>Premium</td>\n",
       "      <td>I</td>\n",
       "      <td>VS2</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>334</td>\n",
       "      <td>4.20</td>\n",
       "      <td>4.23</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.31</td>\n",
       "      <td>Good</td>\n",
       "      <td>J</td>\n",
       "      <td>SI2</td>\n",
       "      <td>63.3</td>\n",
       "      <td>58.0</td>\n",
       "      <td>335</td>\n",
       "      <td>4.34</td>\n",
       "      <td>4.35</td>\n",
       "      <td>2.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53936</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>60.8</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.76</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53937</th>\n",
       "      <td>0.72</td>\n",
       "      <td>Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.69</td>\n",
       "      <td>5.75</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53938</th>\n",
       "      <td>0.70</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>D</td>\n",
       "      <td>SI1</td>\n",
       "      <td>62.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.66</td>\n",
       "      <td>5.68</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53939</th>\n",
       "      <td>0.86</td>\n",
       "      <td>Premium</td>\n",
       "      <td>H</td>\n",
       "      <td>SI2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.12</td>\n",
       "      <td>3.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53940</th>\n",
       "      <td>0.75</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>D</td>\n",
       "      <td>SI2</td>\n",
       "      <td>62.2</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2757</td>\n",
       "      <td>5.83</td>\n",
       "      <td>5.87</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>53940 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       carat        cut color clarity  depth  table  price     x     y     z\n",
       "1       0.23      Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n",
       "2       0.21    Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n",
       "3       0.23       Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n",
       "4       0.29    Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n",
       "5       0.31       Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75\n",
       "...      ...        ...   ...     ...    ...    ...    ...   ...   ...   ...\n",
       "53936   0.72      Ideal     D     SI1   60.8   57.0   2757  5.75  5.76  3.50\n",
       "53937   0.72       Good     D     SI1   63.1   55.0   2757  5.69  5.75  3.61\n",
       "53938   0.70  Very Good     D     SI1   62.8   60.0   2757  5.66  5.68  3.56\n",
       "53939   0.86    Premium     H     SI2   61.0   58.0   2757  6.15  6.12  3.74\n",
       "53940   0.75      Ideal     D     SI2   62.2   55.0   2757  5.83  5.87  3.64\n",
       "\n",
       "[53940 rows x 10 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pydataset\n",
    "pydataset.data('diamonds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d739d363-1712-45e8-818b-1e4f6ce40f07",
   "metadata": {},
   "source": [
    "## Human activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "203d4937-c73c-4d9e-851b-aa8a8836dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', header=None)\n",
    "column_names = [str(i) for i in range(X_test.shape[1])]\n",
    "\n",
    "X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=column_names )\n",
    "X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=column_names)\n",
    "y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+', header=None, names=['action'])\n",
    "y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+', header=None, names=['action']) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca317b44-6f2a-4f5c-8db6-96d02583a660",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d6cbd808-8faf-4fb2-bdff-8cc4a9b2b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9ba9e6a9-3d53-4aae-9044-f4ca0fd1c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bf4212ed-e9db-4134-9752-a5128585ac51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = y_train -1\n",
    "y_train\n",
    "\n",
    "xgb.fit(X_train, y_train, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "65ff7b7e-efef-4dc4-89ca-43fb145a501d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xgb.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "27c6bf04-d1f5-4b3d-b6fd-ea4160415f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test= y_test -1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "564496b7-86fa-47db-a8f3-b9e0edaf8233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       [ True,  True,  True, ..., False, False, False],\n",
       "       ...,\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True],\n",
       "       [False, False, False, ...,  True,  True,  True]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.values == pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7716380a-386b-44df-9e86-1ee792776158",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_temp = y_test.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1206a0f-0a5f-4642-a422-c34230ac87f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9392602646759416"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#accuracy\n",
    "sum(y_test_temp == pred) / len(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16182f1e-975f-456d-bc7b-8fa43277f1e3",
   "metadata": {},
   "source": [
    "#### 조기중단 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "aef86925-f0ba-43f9-b9c5-435ce7754e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.3, stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "65a55441-6379-4d5e-80e1-88c0b00d19d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb =XGBClassifier(n_estimators=400, learning_rate=0.05, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "551a9bc3-675b-46c7-9c7d-f8367234f558",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `eval_metric` in `fit` method is deprecated for better compatibility with scikit-learn, use `eval_metric` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mlogloss:1.67484\tvalidation_1-mlogloss:1.67577\n",
      "[1]\tvalidation_0-mlogloss:1.57260\tvalidation_1-mlogloss:1.57439\n",
      "[2]\tvalidation_0-mlogloss:1.48203\tvalidation_1-mlogloss:1.48488\n",
      "[3]\tvalidation_0-mlogloss:1.40142\tvalidation_1-mlogloss:1.40550\n",
      "[4]\tvalidation_0-mlogloss:1.32503\tvalidation_1-mlogloss:1.32996\n",
      "[5]\tvalidation_0-mlogloss:1.25514\tvalidation_1-mlogloss:1.26069\n",
      "[6]\tvalidation_0-mlogloss:1.19150\tvalidation_1-mlogloss:1.19781\n",
      "[7]\tvalidation_0-mlogloss:1.13320\tvalidation_1-mlogloss:1.14019\n",
      "[8]\tvalidation_0-mlogloss:1.07998\tvalidation_1-mlogloss:1.08724\n",
      "[9]\tvalidation_0-mlogloss:1.02976\tvalidation_1-mlogloss:1.03721\n",
      "[10]\tvalidation_0-mlogloss:0.98273\tvalidation_1-mlogloss:0.99029\n",
      "[11]\tvalidation_0-mlogloss:0.93904\tvalidation_1-mlogloss:0.94693\n",
      "[12]\tvalidation_0-mlogloss:0.89796\tvalidation_1-mlogloss:0.90665\n",
      "[13]\tvalidation_0-mlogloss:0.85940\tvalidation_1-mlogloss:0.86896\n",
      "[14]\tvalidation_0-mlogloss:0.82301\tvalidation_1-mlogloss:0.83311\n",
      "[15]\tvalidation_0-mlogloss:0.78912\tvalidation_1-mlogloss:0.79985\n",
      "[16]\tvalidation_0-mlogloss:0.75679\tvalidation_1-mlogloss:0.76808\n",
      "[17]\tvalidation_0-mlogloss:0.72632\tvalidation_1-mlogloss:0.73830\n",
      "[18]\tvalidation_0-mlogloss:0.69742\tvalidation_1-mlogloss:0.70991\n",
      "[19]\tvalidation_0-mlogloss:0.67015\tvalidation_1-mlogloss:0.68322\n",
      "[20]\tvalidation_0-mlogloss:0.64429\tvalidation_1-mlogloss:0.65820\n",
      "[21]\tvalidation_0-mlogloss:0.61968\tvalidation_1-mlogloss:0.63395\n",
      "[22]\tvalidation_0-mlogloss:0.59644\tvalidation_1-mlogloss:0.61116\n",
      "[23]\tvalidation_0-mlogloss:0.57438\tvalidation_1-mlogloss:0.58935\n",
      "[24]\tvalidation_0-mlogloss:0.55348\tvalidation_1-mlogloss:0.56920\n",
      "[25]\tvalidation_0-mlogloss:0.53342\tvalidation_1-mlogloss:0.54945\n",
      "[26]\tvalidation_0-mlogloss:0.51446\tvalidation_1-mlogloss:0.53080\n",
      "[27]\tvalidation_0-mlogloss:0.49646\tvalidation_1-mlogloss:0.51327\n",
      "[28]\tvalidation_0-mlogloss:0.47938\tvalidation_1-mlogloss:0.49659\n",
      "[29]\tvalidation_0-mlogloss:0.46302\tvalidation_1-mlogloss:0.48061\n",
      "[30]\tvalidation_0-mlogloss:0.44747\tvalidation_1-mlogloss:0.46538\n",
      "[31]\tvalidation_0-mlogloss:0.43246\tvalidation_1-mlogloss:0.45044\n",
      "[32]\tvalidation_0-mlogloss:0.41844\tvalidation_1-mlogloss:0.43652\n",
      "[33]\tvalidation_0-mlogloss:0.40479\tvalidation_1-mlogloss:0.42293\n",
      "[34]\tvalidation_0-mlogloss:0.39197\tvalidation_1-mlogloss:0.41038\n",
      "[35]\tvalidation_0-mlogloss:0.37970\tvalidation_1-mlogloss:0.39833\n",
      "[36]\tvalidation_0-mlogloss:0.36782\tvalidation_1-mlogloss:0.38650\n",
      "[37]\tvalidation_0-mlogloss:0.35655\tvalidation_1-mlogloss:0.37544\n",
      "[38]\tvalidation_0-mlogloss:0.34576\tvalidation_1-mlogloss:0.36463\n",
      "[39]\tvalidation_0-mlogloss:0.33532\tvalidation_1-mlogloss:0.35432\n",
      "[40]\tvalidation_0-mlogloss:0.32544\tvalidation_1-mlogloss:0.34450\n",
      "[41]\tvalidation_0-mlogloss:0.31606\tvalidation_1-mlogloss:0.33535\n",
      "[42]\tvalidation_0-mlogloss:0.30721\tvalidation_1-mlogloss:0.32657\n",
      "[43]\tvalidation_0-mlogloss:0.29847\tvalidation_1-mlogloss:0.31797\n",
      "[44]\tvalidation_0-mlogloss:0.29015\tvalidation_1-mlogloss:0.30973\n",
      "[45]\tvalidation_0-mlogloss:0.28191\tvalidation_1-mlogloss:0.30134\n",
      "[46]\tvalidation_0-mlogloss:0.27416\tvalidation_1-mlogloss:0.29371\n",
      "[47]\tvalidation_0-mlogloss:0.26682\tvalidation_1-mlogloss:0.28642\n",
      "[48]\tvalidation_0-mlogloss:0.25962\tvalidation_1-mlogloss:0.27929\n",
      "[49]\tvalidation_0-mlogloss:0.25288\tvalidation_1-mlogloss:0.27249\n",
      "[50]\tvalidation_0-mlogloss:0.24606\tvalidation_1-mlogloss:0.26595\n",
      "[51]\tvalidation_0-mlogloss:0.23960\tvalidation_1-mlogloss:0.25946\n",
      "[52]\tvalidation_0-mlogloss:0.23348\tvalidation_1-mlogloss:0.25336\n",
      "[53]\tvalidation_0-mlogloss:0.22747\tvalidation_1-mlogloss:0.24743\n",
      "[54]\tvalidation_0-mlogloss:0.22167\tvalidation_1-mlogloss:0.24155\n",
      "[55]\tvalidation_0-mlogloss:0.21613\tvalidation_1-mlogloss:0.23606\n",
      "[56]\tvalidation_0-mlogloss:0.21061\tvalidation_1-mlogloss:0.23056\n",
      "[57]\tvalidation_0-mlogloss:0.20554\tvalidation_1-mlogloss:0.22555\n",
      "[58]\tvalidation_0-mlogloss:0.20068\tvalidation_1-mlogloss:0.22068\n",
      "[59]\tvalidation_0-mlogloss:0.19599\tvalidation_1-mlogloss:0.21584\n",
      "[60]\tvalidation_0-mlogloss:0.19111\tvalidation_1-mlogloss:0.21106\n",
      "[61]\tvalidation_0-mlogloss:0.18680\tvalidation_1-mlogloss:0.20675\n",
      "[62]\tvalidation_0-mlogloss:0.18251\tvalidation_1-mlogloss:0.20255\n",
      "[63]\tvalidation_0-mlogloss:0.17835\tvalidation_1-mlogloss:0.19852\n",
      "[64]\tvalidation_0-mlogloss:0.17439\tvalidation_1-mlogloss:0.19450\n",
      "[65]\tvalidation_0-mlogloss:0.17060\tvalidation_1-mlogloss:0.19094\n",
      "[66]\tvalidation_0-mlogloss:0.16665\tvalidation_1-mlogloss:0.18698\n",
      "[67]\tvalidation_0-mlogloss:0.16300\tvalidation_1-mlogloss:0.18344\n",
      "[68]\tvalidation_0-mlogloss:0.15923\tvalidation_1-mlogloss:0.17974\n",
      "[69]\tvalidation_0-mlogloss:0.15582\tvalidation_1-mlogloss:0.17632\n",
      "[70]\tvalidation_0-mlogloss:0.15241\tvalidation_1-mlogloss:0.17297\n",
      "[71]\tvalidation_0-mlogloss:0.14934\tvalidation_1-mlogloss:0.17004\n",
      "[72]\tvalidation_0-mlogloss:0.14604\tvalidation_1-mlogloss:0.16687\n",
      "[73]\tvalidation_0-mlogloss:0.14293\tvalidation_1-mlogloss:0.16387\n",
      "[74]\tvalidation_0-mlogloss:0.14005\tvalidation_1-mlogloss:0.16097\n",
      "[75]\tvalidation_0-mlogloss:0.13645\tvalidation_1-mlogloss:0.15760\n",
      "[76]\tvalidation_0-mlogloss:0.13361\tvalidation_1-mlogloss:0.15474\n",
      "[77]\tvalidation_0-mlogloss:0.13036\tvalidation_1-mlogloss:0.15163\n",
      "[78]\tvalidation_0-mlogloss:0.12730\tvalidation_1-mlogloss:0.14871\n",
      "[79]\tvalidation_0-mlogloss:0.12452\tvalidation_1-mlogloss:0.14599\n",
      "[80]\tvalidation_0-mlogloss:0.12154\tvalidation_1-mlogloss:0.14320\n",
      "[81]\tvalidation_0-mlogloss:0.11884\tvalidation_1-mlogloss:0.14050\n",
      "[82]\tvalidation_0-mlogloss:0.11604\tvalidation_1-mlogloss:0.13790\n",
      "[83]\tvalidation_0-mlogloss:0.11328\tvalidation_1-mlogloss:0.13517\n",
      "[84]\tvalidation_0-mlogloss:0.11077\tvalidation_1-mlogloss:0.13278\n",
      "[85]\tvalidation_0-mlogloss:0.10845\tvalidation_1-mlogloss:0.13045\n",
      "[86]\tvalidation_0-mlogloss:0.10606\tvalidation_1-mlogloss:0.12831\n",
      "[87]\tvalidation_0-mlogloss:0.10380\tvalidation_1-mlogloss:0.12612\n",
      "[88]\tvalidation_0-mlogloss:0.10152\tvalidation_1-mlogloss:0.12395\n",
      "[89]\tvalidation_0-mlogloss:0.09922\tvalidation_1-mlogloss:0.12169\n",
      "[90]\tvalidation_0-mlogloss:0.09707\tvalidation_1-mlogloss:0.11962\n",
      "[91]\tvalidation_0-mlogloss:0.09509\tvalidation_1-mlogloss:0.11779\n",
      "[92]\tvalidation_0-mlogloss:0.09324\tvalidation_1-mlogloss:0.11608\n",
      "[93]\tvalidation_0-mlogloss:0.09114\tvalidation_1-mlogloss:0.11403\n",
      "[94]\tvalidation_0-mlogloss:0.08942\tvalidation_1-mlogloss:0.11236\n",
      "[95]\tvalidation_0-mlogloss:0.08772\tvalidation_1-mlogloss:0.11073\n",
      "[96]\tvalidation_0-mlogloss:0.08599\tvalidation_1-mlogloss:0.10902\n",
      "[97]\tvalidation_0-mlogloss:0.08430\tvalidation_1-mlogloss:0.10740\n",
      "[98]\tvalidation_0-mlogloss:0.08279\tvalidation_1-mlogloss:0.10603\n",
      "[99]\tvalidation_0-mlogloss:0.08123\tvalidation_1-mlogloss:0.10443\n",
      "[100]\tvalidation_0-mlogloss:0.07971\tvalidation_1-mlogloss:0.10310\n",
      "[101]\tvalidation_0-mlogloss:0.07816\tvalidation_1-mlogloss:0.10169\n",
      "[102]\tvalidation_0-mlogloss:0.07669\tvalidation_1-mlogloss:0.10021\n",
      "[103]\tvalidation_0-mlogloss:0.07545\tvalidation_1-mlogloss:0.09902\n",
      "[104]\tvalidation_0-mlogloss:0.07395\tvalidation_1-mlogloss:0.09758\n",
      "[105]\tvalidation_0-mlogloss:0.07254\tvalidation_1-mlogloss:0.09617\n",
      "[106]\tvalidation_0-mlogloss:0.07113\tvalidation_1-mlogloss:0.09472\n",
      "[107]\tvalidation_0-mlogloss:0.06987\tvalidation_1-mlogloss:0.09345\n",
      "[108]\tvalidation_0-mlogloss:0.06868\tvalidation_1-mlogloss:0.09234\n",
      "[109]\tvalidation_0-mlogloss:0.06754\tvalidation_1-mlogloss:0.09121\n",
      "[110]\tvalidation_0-mlogloss:0.06629\tvalidation_1-mlogloss:0.08997\n",
      "[111]\tvalidation_0-mlogloss:0.06514\tvalidation_1-mlogloss:0.08887\n",
      "[112]\tvalidation_0-mlogloss:0.06412\tvalidation_1-mlogloss:0.08779\n",
      "[113]\tvalidation_0-mlogloss:0.06311\tvalidation_1-mlogloss:0.08677\n",
      "[114]\tvalidation_0-mlogloss:0.06190\tvalidation_1-mlogloss:0.08554\n",
      "[115]\tvalidation_0-mlogloss:0.06082\tvalidation_1-mlogloss:0.08460\n",
      "[116]\tvalidation_0-mlogloss:0.05972\tvalidation_1-mlogloss:0.08350\n",
      "[117]\tvalidation_0-mlogloss:0.05858\tvalidation_1-mlogloss:0.08239\n",
      "[118]\tvalidation_0-mlogloss:0.05769\tvalidation_1-mlogloss:0.08158\n",
      "[119]\tvalidation_0-mlogloss:0.05670\tvalidation_1-mlogloss:0.08062\n",
      "[120]\tvalidation_0-mlogloss:0.05580\tvalidation_1-mlogloss:0.07981\n",
      "[121]\tvalidation_0-mlogloss:0.05486\tvalidation_1-mlogloss:0.07895\n",
      "[122]\tvalidation_0-mlogloss:0.05387\tvalidation_1-mlogloss:0.07792\n",
      "[123]\tvalidation_0-mlogloss:0.05290\tvalidation_1-mlogloss:0.07697\n",
      "[124]\tvalidation_0-mlogloss:0.05195\tvalidation_1-mlogloss:0.07606\n",
      "[125]\tvalidation_0-mlogloss:0.05108\tvalidation_1-mlogloss:0.07521\n",
      "[126]\tvalidation_0-mlogloss:0.05026\tvalidation_1-mlogloss:0.07435\n",
      "[127]\tvalidation_0-mlogloss:0.04948\tvalidation_1-mlogloss:0.07361\n",
      "[128]\tvalidation_0-mlogloss:0.04872\tvalidation_1-mlogloss:0.07281\n",
      "[129]\tvalidation_0-mlogloss:0.04793\tvalidation_1-mlogloss:0.07213\n",
      "[130]\tvalidation_0-mlogloss:0.04703\tvalidation_1-mlogloss:0.07128\n",
      "[131]\tvalidation_0-mlogloss:0.04619\tvalidation_1-mlogloss:0.07054\n",
      "[132]\tvalidation_0-mlogloss:0.04545\tvalidation_1-mlogloss:0.06980\n",
      "[133]\tvalidation_0-mlogloss:0.04475\tvalidation_1-mlogloss:0.06917\n",
      "[134]\tvalidation_0-mlogloss:0.04405\tvalidation_1-mlogloss:0.06844\n",
      "[135]\tvalidation_0-mlogloss:0.04336\tvalidation_1-mlogloss:0.06778\n",
      "[136]\tvalidation_0-mlogloss:0.04274\tvalidation_1-mlogloss:0.06714\n",
      "[137]\tvalidation_0-mlogloss:0.04209\tvalidation_1-mlogloss:0.06652\n",
      "[138]\tvalidation_0-mlogloss:0.04138\tvalidation_1-mlogloss:0.06579\n",
      "[139]\tvalidation_0-mlogloss:0.04076\tvalidation_1-mlogloss:0.06513\n",
      "[140]\tvalidation_0-mlogloss:0.04016\tvalidation_1-mlogloss:0.06456\n",
      "[141]\tvalidation_0-mlogloss:0.03959\tvalidation_1-mlogloss:0.06403\n",
      "[142]\tvalidation_0-mlogloss:0.03896\tvalidation_1-mlogloss:0.06339\n",
      "[143]\tvalidation_0-mlogloss:0.03842\tvalidation_1-mlogloss:0.06279\n",
      "[144]\tvalidation_0-mlogloss:0.03783\tvalidation_1-mlogloss:0.06212\n",
      "[145]\tvalidation_0-mlogloss:0.03730\tvalidation_1-mlogloss:0.06155\n",
      "[146]\tvalidation_0-mlogloss:0.03679\tvalidation_1-mlogloss:0.06094\n",
      "[147]\tvalidation_0-mlogloss:0.03625\tvalidation_1-mlogloss:0.06036\n",
      "[148]\tvalidation_0-mlogloss:0.03574\tvalidation_1-mlogloss:0.05980\n",
      "[149]\tvalidation_0-mlogloss:0.03524\tvalidation_1-mlogloss:0.05934\n",
      "[150]\tvalidation_0-mlogloss:0.03466\tvalidation_1-mlogloss:0.05878\n",
      "[151]\tvalidation_0-mlogloss:0.03421\tvalidation_1-mlogloss:0.05831\n",
      "[152]\tvalidation_0-mlogloss:0.03375\tvalidation_1-mlogloss:0.05784\n",
      "[153]\tvalidation_0-mlogloss:0.03327\tvalidation_1-mlogloss:0.05730\n",
      "[154]\tvalidation_0-mlogloss:0.03277\tvalidation_1-mlogloss:0.05679\n",
      "[155]\tvalidation_0-mlogloss:0.03221\tvalidation_1-mlogloss:0.05618\n",
      "[156]\tvalidation_0-mlogloss:0.03181\tvalidation_1-mlogloss:0.05574\n",
      "[157]\tvalidation_0-mlogloss:0.03135\tvalidation_1-mlogloss:0.05528\n",
      "[158]\tvalidation_0-mlogloss:0.03094\tvalidation_1-mlogloss:0.05480\n",
      "[159]\tvalidation_0-mlogloss:0.03051\tvalidation_1-mlogloss:0.05430\n",
      "[160]\tvalidation_0-mlogloss:0.03013\tvalidation_1-mlogloss:0.05386\n",
      "[161]\tvalidation_0-mlogloss:0.02973\tvalidation_1-mlogloss:0.05346\n",
      "[162]\tvalidation_0-mlogloss:0.02934\tvalidation_1-mlogloss:0.05303\n",
      "[163]\tvalidation_0-mlogloss:0.02891\tvalidation_1-mlogloss:0.05249\n",
      "[164]\tvalidation_0-mlogloss:0.02854\tvalidation_1-mlogloss:0.05208\n",
      "[165]\tvalidation_0-mlogloss:0.02811\tvalidation_1-mlogloss:0.05162\n",
      "[166]\tvalidation_0-mlogloss:0.02776\tvalidation_1-mlogloss:0.05117\n",
      "[167]\tvalidation_0-mlogloss:0.02737\tvalidation_1-mlogloss:0.05078\n",
      "[168]\tvalidation_0-mlogloss:0.02700\tvalidation_1-mlogloss:0.05035\n",
      "[169]\tvalidation_0-mlogloss:0.02667\tvalidation_1-mlogloss:0.05008\n",
      "[170]\tvalidation_0-mlogloss:0.02638\tvalidation_1-mlogloss:0.04980\n",
      "[171]\tvalidation_0-mlogloss:0.02601\tvalidation_1-mlogloss:0.04945\n",
      "[172]\tvalidation_0-mlogloss:0.02562\tvalidation_1-mlogloss:0.04899\n",
      "[173]\tvalidation_0-mlogloss:0.02525\tvalidation_1-mlogloss:0.04860\n",
      "[174]\tvalidation_0-mlogloss:0.02496\tvalidation_1-mlogloss:0.04825\n",
      "[175]\tvalidation_0-mlogloss:0.02457\tvalidation_1-mlogloss:0.04787\n",
      "[176]\tvalidation_0-mlogloss:0.02424\tvalidation_1-mlogloss:0.04748\n",
      "[177]\tvalidation_0-mlogloss:0.02391\tvalidation_1-mlogloss:0.04714\n",
      "[178]\tvalidation_0-mlogloss:0.02365\tvalidation_1-mlogloss:0.04691\n",
      "[179]\tvalidation_0-mlogloss:0.02334\tvalidation_1-mlogloss:0.04657\n",
      "[180]\tvalidation_0-mlogloss:0.02302\tvalidation_1-mlogloss:0.04620\n",
      "[181]\tvalidation_0-mlogloss:0.02275\tvalidation_1-mlogloss:0.04590\n",
      "[182]\tvalidation_0-mlogloss:0.02243\tvalidation_1-mlogloss:0.04556\n",
      "[183]\tvalidation_0-mlogloss:0.02220\tvalidation_1-mlogloss:0.04535\n",
      "[184]\tvalidation_0-mlogloss:0.02189\tvalidation_1-mlogloss:0.04505\n",
      "[185]\tvalidation_0-mlogloss:0.02162\tvalidation_1-mlogloss:0.04473\n",
      "[186]\tvalidation_0-mlogloss:0.02138\tvalidation_1-mlogloss:0.04452\n",
      "[187]\tvalidation_0-mlogloss:0.02111\tvalidation_1-mlogloss:0.04415\n",
      "[188]\tvalidation_0-mlogloss:0.02088\tvalidation_1-mlogloss:0.04388\n",
      "[189]\tvalidation_0-mlogloss:0.02061\tvalidation_1-mlogloss:0.04359\n",
      "[190]\tvalidation_0-mlogloss:0.02035\tvalidation_1-mlogloss:0.04326\n",
      "[191]\tvalidation_0-mlogloss:0.02014\tvalidation_1-mlogloss:0.04309\n",
      "[192]\tvalidation_0-mlogloss:0.01987\tvalidation_1-mlogloss:0.04278\n",
      "[193]\tvalidation_0-mlogloss:0.01964\tvalidation_1-mlogloss:0.04256\n",
      "[194]\tvalidation_0-mlogloss:0.01940\tvalidation_1-mlogloss:0.04230\n",
      "[195]\tvalidation_0-mlogloss:0.01916\tvalidation_1-mlogloss:0.04199\n",
      "[196]\tvalidation_0-mlogloss:0.01898\tvalidation_1-mlogloss:0.04178\n",
      "[197]\tvalidation_0-mlogloss:0.01875\tvalidation_1-mlogloss:0.04150\n",
      "[198]\tvalidation_0-mlogloss:0.01856\tvalidation_1-mlogloss:0.04130\n",
      "[199]\tvalidation_0-mlogloss:0.01835\tvalidation_1-mlogloss:0.04106\n",
      "[200]\tvalidation_0-mlogloss:0.01812\tvalidation_1-mlogloss:0.04082\n",
      "[201]\tvalidation_0-mlogloss:0.01792\tvalidation_1-mlogloss:0.04055\n",
      "[202]\tvalidation_0-mlogloss:0.01773\tvalidation_1-mlogloss:0.04037\n",
      "[203]\tvalidation_0-mlogloss:0.01754\tvalidation_1-mlogloss:0.04011\n",
      "[204]\tvalidation_0-mlogloss:0.01733\tvalidation_1-mlogloss:0.03988\n",
      "[205]\tvalidation_0-mlogloss:0.01715\tvalidation_1-mlogloss:0.03968\n",
      "[206]\tvalidation_0-mlogloss:0.01697\tvalidation_1-mlogloss:0.03945\n",
      "[207]\tvalidation_0-mlogloss:0.01680\tvalidation_1-mlogloss:0.03929\n",
      "[208]\tvalidation_0-mlogloss:0.01665\tvalidation_1-mlogloss:0.03912\n",
      "[209]\tvalidation_0-mlogloss:0.01647\tvalidation_1-mlogloss:0.03894\n",
      "[210]\tvalidation_0-mlogloss:0.01625\tvalidation_1-mlogloss:0.03870\n",
      "[211]\tvalidation_0-mlogloss:0.01606\tvalidation_1-mlogloss:0.03843\n",
      "[212]\tvalidation_0-mlogloss:0.01589\tvalidation_1-mlogloss:0.03828\n",
      "[213]\tvalidation_0-mlogloss:0.01571\tvalidation_1-mlogloss:0.03811\n",
      "[214]\tvalidation_0-mlogloss:0.01556\tvalidation_1-mlogloss:0.03789\n",
      "[215]\tvalidation_0-mlogloss:0.01538\tvalidation_1-mlogloss:0.03767\n",
      "[216]\tvalidation_0-mlogloss:0.01520\tvalidation_1-mlogloss:0.03747\n",
      "[217]\tvalidation_0-mlogloss:0.01506\tvalidation_1-mlogloss:0.03737\n",
      "[218]\tvalidation_0-mlogloss:0.01487\tvalidation_1-mlogloss:0.03715\n",
      "[219]\tvalidation_0-mlogloss:0.01472\tvalidation_1-mlogloss:0.03699\n",
      "[220]\tvalidation_0-mlogloss:0.01458\tvalidation_1-mlogloss:0.03681\n",
      "[221]\tvalidation_0-mlogloss:0.01443\tvalidation_1-mlogloss:0.03665\n",
      "[222]\tvalidation_0-mlogloss:0.01428\tvalidation_1-mlogloss:0.03650\n",
      "[223]\tvalidation_0-mlogloss:0.01413\tvalidation_1-mlogloss:0.03636\n",
      "[224]\tvalidation_0-mlogloss:0.01399\tvalidation_1-mlogloss:0.03619\n",
      "[225]\tvalidation_0-mlogloss:0.01387\tvalidation_1-mlogloss:0.03603\n",
      "[226]\tvalidation_0-mlogloss:0.01370\tvalidation_1-mlogloss:0.03582\n",
      "[227]\tvalidation_0-mlogloss:0.01355\tvalidation_1-mlogloss:0.03568\n",
      "[228]\tvalidation_0-mlogloss:0.01341\tvalidation_1-mlogloss:0.03559\n",
      "[229]\tvalidation_0-mlogloss:0.01329\tvalidation_1-mlogloss:0.03542\n",
      "[230]\tvalidation_0-mlogloss:0.01315\tvalidation_1-mlogloss:0.03527\n",
      "[231]\tvalidation_0-mlogloss:0.01301\tvalidation_1-mlogloss:0.03509\n",
      "[232]\tvalidation_0-mlogloss:0.01288\tvalidation_1-mlogloss:0.03490\n",
      "[233]\tvalidation_0-mlogloss:0.01274\tvalidation_1-mlogloss:0.03473\n",
      "[234]\tvalidation_0-mlogloss:0.01261\tvalidation_1-mlogloss:0.03455\n",
      "[235]\tvalidation_0-mlogloss:0.01250\tvalidation_1-mlogloss:0.03444\n",
      "[236]\tvalidation_0-mlogloss:0.01239\tvalidation_1-mlogloss:0.03435\n",
      "[237]\tvalidation_0-mlogloss:0.01228\tvalidation_1-mlogloss:0.03424\n",
      "[238]\tvalidation_0-mlogloss:0.01216\tvalidation_1-mlogloss:0.03413\n",
      "[239]\tvalidation_0-mlogloss:0.01205\tvalidation_1-mlogloss:0.03403\n",
      "[240]\tvalidation_0-mlogloss:0.01191\tvalidation_1-mlogloss:0.03388\n",
      "[241]\tvalidation_0-mlogloss:0.01177\tvalidation_1-mlogloss:0.03371\n",
      "[242]\tvalidation_0-mlogloss:0.01166\tvalidation_1-mlogloss:0.03357\n",
      "[243]\tvalidation_0-mlogloss:0.01153\tvalidation_1-mlogloss:0.03341\n",
      "[244]\tvalidation_0-mlogloss:0.01142\tvalidation_1-mlogloss:0.03327\n",
      "[245]\tvalidation_0-mlogloss:0.01130\tvalidation_1-mlogloss:0.03308\n",
      "[246]\tvalidation_0-mlogloss:0.01119\tvalidation_1-mlogloss:0.03289\n",
      "[247]\tvalidation_0-mlogloss:0.01111\tvalidation_1-mlogloss:0.03280\n",
      "[248]\tvalidation_0-mlogloss:0.01101\tvalidation_1-mlogloss:0.03271\n",
      "[249]\tvalidation_0-mlogloss:0.01088\tvalidation_1-mlogloss:0.03253\n",
      "[250]\tvalidation_0-mlogloss:0.01078\tvalidation_1-mlogloss:0.03242\n",
      "[251]\tvalidation_0-mlogloss:0.01067\tvalidation_1-mlogloss:0.03229\n",
      "[252]\tvalidation_0-mlogloss:0.01057\tvalidation_1-mlogloss:0.03219\n",
      "[253]\tvalidation_0-mlogloss:0.01048\tvalidation_1-mlogloss:0.03208\n",
      "[254]\tvalidation_0-mlogloss:0.01038\tvalidation_1-mlogloss:0.03199\n",
      "[255]\tvalidation_0-mlogloss:0.01029\tvalidation_1-mlogloss:0.03188\n",
      "[256]\tvalidation_0-mlogloss:0.01018\tvalidation_1-mlogloss:0.03170\n",
      "[257]\tvalidation_0-mlogloss:0.01008\tvalidation_1-mlogloss:0.03155\n",
      "[258]\tvalidation_0-mlogloss:0.00998\tvalidation_1-mlogloss:0.03138\n",
      "[259]\tvalidation_0-mlogloss:0.00989\tvalidation_1-mlogloss:0.03129\n",
      "[260]\tvalidation_0-mlogloss:0.00982\tvalidation_1-mlogloss:0.03127\n",
      "[261]\tvalidation_0-mlogloss:0.00972\tvalidation_1-mlogloss:0.03110\n",
      "[262]\tvalidation_0-mlogloss:0.00962\tvalidation_1-mlogloss:0.03093\n",
      "[263]\tvalidation_0-mlogloss:0.00955\tvalidation_1-mlogloss:0.03083\n",
      "[264]\tvalidation_0-mlogloss:0.00946\tvalidation_1-mlogloss:0.03071\n",
      "[265]\tvalidation_0-mlogloss:0.00936\tvalidation_1-mlogloss:0.03056\n",
      "[266]\tvalidation_0-mlogloss:0.00927\tvalidation_1-mlogloss:0.03046\n",
      "[267]\tvalidation_0-mlogloss:0.00917\tvalidation_1-mlogloss:0.03035\n",
      "[268]\tvalidation_0-mlogloss:0.00909\tvalidation_1-mlogloss:0.03023\n",
      "[269]\tvalidation_0-mlogloss:0.00898\tvalidation_1-mlogloss:0.03006\n",
      "[270]\tvalidation_0-mlogloss:0.00891\tvalidation_1-mlogloss:0.02999\n",
      "[271]\tvalidation_0-mlogloss:0.00884\tvalidation_1-mlogloss:0.02989\n",
      "[272]\tvalidation_0-mlogloss:0.00874\tvalidation_1-mlogloss:0.02975\n",
      "[273]\tvalidation_0-mlogloss:0.00865\tvalidation_1-mlogloss:0.02962\n",
      "[274]\tvalidation_0-mlogloss:0.00857\tvalidation_1-mlogloss:0.02950\n",
      "[275]\tvalidation_0-mlogloss:0.00849\tvalidation_1-mlogloss:0.02938\n",
      "[276]\tvalidation_0-mlogloss:0.00839\tvalidation_1-mlogloss:0.02925\n",
      "[277]\tvalidation_0-mlogloss:0.00832\tvalidation_1-mlogloss:0.02917\n",
      "[278]\tvalidation_0-mlogloss:0.00824\tvalidation_1-mlogloss:0.02904\n",
      "[279]\tvalidation_0-mlogloss:0.00815\tvalidation_1-mlogloss:0.02886\n",
      "[280]\tvalidation_0-mlogloss:0.00807\tvalidation_1-mlogloss:0.02880\n",
      "[281]\tvalidation_0-mlogloss:0.00799\tvalidation_1-mlogloss:0.02870\n",
      "[282]\tvalidation_0-mlogloss:0.00791\tvalidation_1-mlogloss:0.02855\n",
      "[283]\tvalidation_0-mlogloss:0.00786\tvalidation_1-mlogloss:0.02849\n",
      "[284]\tvalidation_0-mlogloss:0.00779\tvalidation_1-mlogloss:0.02841\n",
      "[285]\tvalidation_0-mlogloss:0.00770\tvalidation_1-mlogloss:0.02825\n",
      "[286]\tvalidation_0-mlogloss:0.00764\tvalidation_1-mlogloss:0.02817\n",
      "[287]\tvalidation_0-mlogloss:0.00757\tvalidation_1-mlogloss:0.02809\n",
      "[288]\tvalidation_0-mlogloss:0.00752\tvalidation_1-mlogloss:0.02803\n",
      "[289]\tvalidation_0-mlogloss:0.00745\tvalidation_1-mlogloss:0.02796\n",
      "[290]\tvalidation_0-mlogloss:0.00737\tvalidation_1-mlogloss:0.02788\n",
      "[291]\tvalidation_0-mlogloss:0.00731\tvalidation_1-mlogloss:0.02780\n",
      "[292]\tvalidation_0-mlogloss:0.00725\tvalidation_1-mlogloss:0.02771\n",
      "[293]\tvalidation_0-mlogloss:0.00719\tvalidation_1-mlogloss:0.02767\n",
      "[294]\tvalidation_0-mlogloss:0.00712\tvalidation_1-mlogloss:0.02757\n",
      "[295]\tvalidation_0-mlogloss:0.00707\tvalidation_1-mlogloss:0.02746\n",
      "[296]\tvalidation_0-mlogloss:0.00701\tvalidation_1-mlogloss:0.02741\n",
      "[297]\tvalidation_0-mlogloss:0.00695\tvalidation_1-mlogloss:0.02731\n",
      "[298]\tvalidation_0-mlogloss:0.00689\tvalidation_1-mlogloss:0.02722\n",
      "[299]\tvalidation_0-mlogloss:0.00685\tvalidation_1-mlogloss:0.02715\n",
      "[300]\tvalidation_0-mlogloss:0.00678\tvalidation_1-mlogloss:0.02707\n",
      "[301]\tvalidation_0-mlogloss:0.00672\tvalidation_1-mlogloss:0.02699\n",
      "[302]\tvalidation_0-mlogloss:0.00668\tvalidation_1-mlogloss:0.02693\n",
      "[303]\tvalidation_0-mlogloss:0.00662\tvalidation_1-mlogloss:0.02679\n",
      "[304]\tvalidation_0-mlogloss:0.00655\tvalidation_1-mlogloss:0.02668\n",
      "[305]\tvalidation_0-mlogloss:0.00650\tvalidation_1-mlogloss:0.02662\n",
      "[306]\tvalidation_0-mlogloss:0.00645\tvalidation_1-mlogloss:0.02654\n",
      "[307]\tvalidation_0-mlogloss:0.00640\tvalidation_1-mlogloss:0.02649\n",
      "[308]\tvalidation_0-mlogloss:0.00634\tvalidation_1-mlogloss:0.02639\n",
      "[309]\tvalidation_0-mlogloss:0.00629\tvalidation_1-mlogloss:0.02631\n",
      "[310]\tvalidation_0-mlogloss:0.00624\tvalidation_1-mlogloss:0.02623\n",
      "[311]\tvalidation_0-mlogloss:0.00619\tvalidation_1-mlogloss:0.02617\n",
      "[312]\tvalidation_0-mlogloss:0.00613\tvalidation_1-mlogloss:0.02612\n",
      "[313]\tvalidation_0-mlogloss:0.00608\tvalidation_1-mlogloss:0.02602\n",
      "[314]\tvalidation_0-mlogloss:0.00604\tvalidation_1-mlogloss:0.02595\n",
      "[315]\tvalidation_0-mlogloss:0.00600\tvalidation_1-mlogloss:0.02593\n",
      "[316]\tvalidation_0-mlogloss:0.00595\tvalidation_1-mlogloss:0.02586\n",
      "[317]\tvalidation_0-mlogloss:0.00590\tvalidation_1-mlogloss:0.02583\n",
      "[318]\tvalidation_0-mlogloss:0.00585\tvalidation_1-mlogloss:0.02576\n",
      "[319]\tvalidation_0-mlogloss:0.00581\tvalidation_1-mlogloss:0.02568\n",
      "[320]\tvalidation_0-mlogloss:0.00576\tvalidation_1-mlogloss:0.02561\n",
      "[321]\tvalidation_0-mlogloss:0.00572\tvalidation_1-mlogloss:0.02555\n",
      "[322]\tvalidation_0-mlogloss:0.00567\tvalidation_1-mlogloss:0.02547\n",
      "[323]\tvalidation_0-mlogloss:0.00562\tvalidation_1-mlogloss:0.02545\n",
      "[324]\tvalidation_0-mlogloss:0.00558\tvalidation_1-mlogloss:0.02544\n",
      "[325]\tvalidation_0-mlogloss:0.00554\tvalidation_1-mlogloss:0.02536\n",
      "[326]\tvalidation_0-mlogloss:0.00550\tvalidation_1-mlogloss:0.02533\n",
      "[327]\tvalidation_0-mlogloss:0.00546\tvalidation_1-mlogloss:0.02528\n",
      "[328]\tvalidation_0-mlogloss:0.00542\tvalidation_1-mlogloss:0.02519\n",
      "[329]\tvalidation_0-mlogloss:0.00537\tvalidation_1-mlogloss:0.02513\n",
      "[330]\tvalidation_0-mlogloss:0.00533\tvalidation_1-mlogloss:0.02508\n",
      "[331]\tvalidation_0-mlogloss:0.00530\tvalidation_1-mlogloss:0.02503\n",
      "[332]\tvalidation_0-mlogloss:0.00527\tvalidation_1-mlogloss:0.02500\n",
      "[333]\tvalidation_0-mlogloss:0.00522\tvalidation_1-mlogloss:0.02492\n",
      "[334]\tvalidation_0-mlogloss:0.00519\tvalidation_1-mlogloss:0.02489\n",
      "[335]\tvalidation_0-mlogloss:0.00515\tvalidation_1-mlogloss:0.02478\n",
      "[336]\tvalidation_0-mlogloss:0.00511\tvalidation_1-mlogloss:0.02473\n",
      "[337]\tvalidation_0-mlogloss:0.00507\tvalidation_1-mlogloss:0.02469\n",
      "[338]\tvalidation_0-mlogloss:0.00503\tvalidation_1-mlogloss:0.02465\n",
      "[339]\tvalidation_0-mlogloss:0.00500\tvalidation_1-mlogloss:0.02461\n",
      "[340]\tvalidation_0-mlogloss:0.00496\tvalidation_1-mlogloss:0.02455\n",
      "[341]\tvalidation_0-mlogloss:0.00492\tvalidation_1-mlogloss:0.02448\n",
      "[342]\tvalidation_0-mlogloss:0.00490\tvalidation_1-mlogloss:0.02445\n",
      "[343]\tvalidation_0-mlogloss:0.00485\tvalidation_1-mlogloss:0.02436\n",
      "[344]\tvalidation_0-mlogloss:0.00482\tvalidation_1-mlogloss:0.02434\n",
      "[345]\tvalidation_0-mlogloss:0.00478\tvalidation_1-mlogloss:0.02431\n",
      "[346]\tvalidation_0-mlogloss:0.00476\tvalidation_1-mlogloss:0.02428\n",
      "[347]\tvalidation_0-mlogloss:0.00472\tvalidation_1-mlogloss:0.02423\n",
      "[348]\tvalidation_0-mlogloss:0.00469\tvalidation_1-mlogloss:0.02419\n",
      "[349]\tvalidation_0-mlogloss:0.00466\tvalidation_1-mlogloss:0.02415\n",
      "[350]\tvalidation_0-mlogloss:0.00462\tvalidation_1-mlogloss:0.02410\n",
      "[351]\tvalidation_0-mlogloss:0.00458\tvalidation_1-mlogloss:0.02402\n",
      "[352]\tvalidation_0-mlogloss:0.00455\tvalidation_1-mlogloss:0.02400\n",
      "[353]\tvalidation_0-mlogloss:0.00452\tvalidation_1-mlogloss:0.02396\n",
      "[354]\tvalidation_0-mlogloss:0.00449\tvalidation_1-mlogloss:0.02390\n",
      "[355]\tvalidation_0-mlogloss:0.00446\tvalidation_1-mlogloss:0.02384\n",
      "[356]\tvalidation_0-mlogloss:0.00442\tvalidation_1-mlogloss:0.02380\n",
      "[357]\tvalidation_0-mlogloss:0.00440\tvalidation_1-mlogloss:0.02374\n",
      "[358]\tvalidation_0-mlogloss:0.00437\tvalidation_1-mlogloss:0.02366\n",
      "[359]\tvalidation_0-mlogloss:0.00434\tvalidation_1-mlogloss:0.02360\n",
      "[360]\tvalidation_0-mlogloss:0.00431\tvalidation_1-mlogloss:0.02352\n",
      "[361]\tvalidation_0-mlogloss:0.00429\tvalidation_1-mlogloss:0.02346\n",
      "[362]\tvalidation_0-mlogloss:0.00426\tvalidation_1-mlogloss:0.02341\n",
      "[363]\tvalidation_0-mlogloss:0.00423\tvalidation_1-mlogloss:0.02337\n",
      "[364]\tvalidation_0-mlogloss:0.00420\tvalidation_1-mlogloss:0.02331\n",
      "[365]\tvalidation_0-mlogloss:0.00418\tvalidation_1-mlogloss:0.02329\n",
      "[366]\tvalidation_0-mlogloss:0.00416\tvalidation_1-mlogloss:0.02323\n",
      "[367]\tvalidation_0-mlogloss:0.00413\tvalidation_1-mlogloss:0.02317\n",
      "[368]\tvalidation_0-mlogloss:0.00410\tvalidation_1-mlogloss:0.02314\n",
      "[369]\tvalidation_0-mlogloss:0.00408\tvalidation_1-mlogloss:0.02311\n",
      "[370]\tvalidation_0-mlogloss:0.00405\tvalidation_1-mlogloss:0.02306\n",
      "[371]\tvalidation_0-mlogloss:0.00403\tvalidation_1-mlogloss:0.02302\n",
      "[372]\tvalidation_0-mlogloss:0.00401\tvalidation_1-mlogloss:0.02298\n",
      "[373]\tvalidation_0-mlogloss:0.00398\tvalidation_1-mlogloss:0.02293\n",
      "[374]\tvalidation_0-mlogloss:0.00396\tvalidation_1-mlogloss:0.02290\n",
      "[375]\tvalidation_0-mlogloss:0.00393\tvalidation_1-mlogloss:0.02289\n",
      "[376]\tvalidation_0-mlogloss:0.00391\tvalidation_1-mlogloss:0.02284\n",
      "[377]\tvalidation_0-mlogloss:0.00389\tvalidation_1-mlogloss:0.02277\n",
      "[378]\tvalidation_0-mlogloss:0.00386\tvalidation_1-mlogloss:0.02274\n",
      "[379]\tvalidation_0-mlogloss:0.00383\tvalidation_1-mlogloss:0.02268\n",
      "[380]\tvalidation_0-mlogloss:0.00380\tvalidation_1-mlogloss:0.02265\n",
      "[381]\tvalidation_0-mlogloss:0.00377\tvalidation_1-mlogloss:0.02258\n",
      "[382]\tvalidation_0-mlogloss:0.00376\tvalidation_1-mlogloss:0.02256\n",
      "[383]\tvalidation_0-mlogloss:0.00373\tvalidation_1-mlogloss:0.02251\n",
      "[384]\tvalidation_0-mlogloss:0.00371\tvalidation_1-mlogloss:0.02244\n",
      "[385]\tvalidation_0-mlogloss:0.00369\tvalidation_1-mlogloss:0.02240\n",
      "[386]\tvalidation_0-mlogloss:0.00366\tvalidation_1-mlogloss:0.02240\n",
      "[387]\tvalidation_0-mlogloss:0.00364\tvalidation_1-mlogloss:0.02234\n",
      "[388]\tvalidation_0-mlogloss:0.00361\tvalidation_1-mlogloss:0.02227\n",
      "[389]\tvalidation_0-mlogloss:0.00359\tvalidation_1-mlogloss:0.02225\n",
      "[390]\tvalidation_0-mlogloss:0.00357\tvalidation_1-mlogloss:0.02220\n",
      "[391]\tvalidation_0-mlogloss:0.00355\tvalidation_1-mlogloss:0.02220\n",
      "[392]\tvalidation_0-mlogloss:0.00353\tvalidation_1-mlogloss:0.02213\n",
      "[393]\tvalidation_0-mlogloss:0.00351\tvalidation_1-mlogloss:0.02209\n",
      "[394]\tvalidation_0-mlogloss:0.00349\tvalidation_1-mlogloss:0.02207\n",
      "[395]\tvalidation_0-mlogloss:0.00347\tvalidation_1-mlogloss:0.02205\n",
      "[396]\tvalidation_0-mlogloss:0.00345\tvalidation_1-mlogloss:0.02200\n",
      "[397]\tvalidation_0-mlogloss:0.00344\tvalidation_1-mlogloss:0.02197\n",
      "[398]\tvalidation_0-mlogloss:0.00341\tvalidation_1-mlogloss:0.02192\n",
      "[399]\tvalidation_0-mlogloss:0.00340\tvalidation_1-mlogloss:0.02191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "              num_parallel_tree=None, objective=&#x27;multi:softprob&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=400, n_jobs=None,\n",
       "              num_parallel_tree=None, objective='multi:softprob', ...)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals = [(X_tr, y_tr),(X_val, y_val)]\n",
    "xgb.fit(X_tr,y_tr, early_stopping_rounds=50, eval_metric='mlogloss', eval_set=evals, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "bf6470b6-ab27-434b-9594-6c11a98fe618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4, 4, 4, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = xgb.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ecce0cbc-db93-4ea4-a3d4-dfc79c1ec9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9457074991516796"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f029bd-f7f2-4da2-9713-69916d5bd131",
   "metadata": {},
   "source": [
    "#### feature importance 그래프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "73cba9e8-3080-4049-9826-6e9c75b0df5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Feature importance'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,12))\n",
    "plot_importance(xgb, ax=ax, max_num_features=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448f8e04-16a4-49f7-ab0b-b55515280ab5",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "07f880cd-1d47-4ea7-8a96-c9fb6b18e401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install lightgbm==3.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e77b5c89-b2b1-430e-8202-058b32787bad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\sklearn.py:726: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "C:\\Users\\admin\\AppData\\Roaming\\Python\\Python310\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\ttraining's multi_logloss: 1.55918\tvalid_1's multi_logloss: 1.57407\n",
      "[2]\ttraining's multi_logloss: 1.38412\tvalid_1's multi_logloss: 1.40892\n",
      "[3]\ttraining's multi_logloss: 1.24019\tvalid_1's multi_logloss: 1.27428\n",
      "[4]\ttraining's multi_logloss: 1.11809\tvalid_1's multi_logloss: 1.15708\n",
      "[5]\ttraining's multi_logloss: 1.01212\tvalid_1's multi_logloss: 1.05473\n",
      "[6]\ttraining's multi_logloss: 0.919102\tvalid_1's multi_logloss: 0.965531\n",
      "[7]\ttraining's multi_logloss: 0.836745\tvalid_1's multi_logloss: 0.886189\n",
      "[8]\ttraining's multi_logloss: 0.763752\tvalid_1's multi_logloss: 0.816363\n",
      "[9]\ttraining's multi_logloss: 0.698336\tvalid_1's multi_logloss: 0.754014\n",
      "[10]\ttraining's multi_logloss: 0.63963\tvalid_1's multi_logloss: 0.698009\n",
      "[11]\ttraining's multi_logloss: 0.586809\tvalid_1's multi_logloss: 0.646942\n",
      "[12]\ttraining's multi_logloss: 0.538873\tvalid_1's multi_logloss: 0.600083\n",
      "[13]\ttraining's multi_logloss: 0.49545\tvalid_1's multi_logloss: 0.558486\n",
      "[14]\ttraining's multi_logloss: 0.456029\tvalid_1's multi_logloss: 0.519861\n",
      "[15]\ttraining's multi_logloss: 0.420076\tvalid_1's multi_logloss: 0.484225\n",
      "[16]\ttraining's multi_logloss: 0.387047\tvalid_1's multi_logloss: 0.451311\n",
      "[17]\ttraining's multi_logloss: 0.356879\tvalid_1's multi_logloss: 0.42103\n",
      "[18]\ttraining's multi_logloss: 0.329387\tvalid_1's multi_logloss: 0.393812\n",
      "[19]\ttraining's multi_logloss: 0.303982\tvalid_1's multi_logloss: 0.36828\n",
      "[20]\ttraining's multi_logloss: 0.280746\tvalid_1's multi_logloss: 0.344957\n",
      "[21]\ttraining's multi_logloss: 0.259283\tvalid_1's multi_logloss: 0.323223\n",
      "[22]\ttraining's multi_logloss: 0.239746\tvalid_1's multi_logloss: 0.303169\n",
      "[23]\ttraining's multi_logloss: 0.221653\tvalid_1's multi_logloss: 0.284404\n",
      "[24]\ttraining's multi_logloss: 0.204891\tvalid_1's multi_logloss: 0.26689\n",
      "[25]\ttraining's multi_logloss: 0.18937\tvalid_1's multi_logloss: 0.250889\n",
      "[26]\ttraining's multi_logloss: 0.1752\tvalid_1's multi_logloss: 0.23584\n",
      "[27]\ttraining's multi_logloss: 0.162154\tvalid_1's multi_logloss: 0.222476\n",
      "[28]\ttraining's multi_logloss: 0.150102\tvalid_1's multi_logloss: 0.209689\n",
      "[29]\ttraining's multi_logloss: 0.139009\tvalid_1's multi_logloss: 0.197983\n",
      "[30]\ttraining's multi_logloss: 0.128728\tvalid_1's multi_logloss: 0.187205\n",
      "[31]\ttraining's multi_logloss: 0.119192\tvalid_1's multi_logloss: 0.176469\n",
      "[32]\ttraining's multi_logloss: 0.11041\tvalid_1's multi_logloss: 0.16717\n",
      "[33]\ttraining's multi_logloss: 0.102289\tvalid_1's multi_logloss: 0.158602\n",
      "[34]\ttraining's multi_logloss: 0.094731\tvalid_1's multi_logloss: 0.150489\n",
      "[35]\ttraining's multi_logloss: 0.087737\tvalid_1's multi_logloss: 0.142837\n",
      "[36]\ttraining's multi_logloss: 0.0812818\tvalid_1's multi_logloss: 0.135579\n",
      "[37]\ttraining's multi_logloss: 0.0753307\tvalid_1's multi_logloss: 0.129112\n",
      "[38]\ttraining's multi_logloss: 0.0698246\tvalid_1's multi_logloss: 0.123329\n",
      "[39]\ttraining's multi_logloss: 0.0647735\tvalid_1's multi_logloss: 0.117351\n",
      "[40]\ttraining's multi_logloss: 0.0600726\tvalid_1's multi_logloss: 0.11187\n",
      "[41]\ttraining's multi_logloss: 0.0557507\tvalid_1's multi_logloss: 0.106924\n",
      "[42]\ttraining's multi_logloss: 0.0516957\tvalid_1's multi_logloss: 0.101994\n",
      "[43]\ttraining's multi_logloss: 0.0479849\tvalid_1's multi_logloss: 0.0979492\n",
      "[44]\ttraining's multi_logloss: 0.0445432\tvalid_1's multi_logloss: 0.0940286\n",
      "[45]\ttraining's multi_logloss: 0.0413429\tvalid_1's multi_logloss: 0.0900797\n",
      "[46]\ttraining's multi_logloss: 0.038392\tvalid_1's multi_logloss: 0.0866484\n",
      "[47]\ttraining's multi_logloss: 0.0356205\tvalid_1's multi_logloss: 0.0835058\n",
      "[48]\ttraining's multi_logloss: 0.033034\tvalid_1's multi_logloss: 0.0805978\n",
      "[49]\ttraining's multi_logloss: 0.0306596\tvalid_1's multi_logloss: 0.0777438\n",
      "[50]\ttraining's multi_logloss: 0.0284529\tvalid_1's multi_logloss: 0.0752057\n",
      "[51]\ttraining's multi_logloss: 0.0264107\tvalid_1's multi_logloss: 0.07254\n",
      "[52]\ttraining's multi_logloss: 0.0245186\tvalid_1's multi_logloss: 0.0700534\n",
      "[53]\ttraining's multi_logloss: 0.0227781\tvalid_1's multi_logloss: 0.0676717\n",
      "[54]\ttraining's multi_logloss: 0.0211455\tvalid_1's multi_logloss: 0.0653823\n",
      "[55]\ttraining's multi_logloss: 0.0196522\tvalid_1's multi_logloss: 0.0632177\n",
      "[56]\ttraining's multi_logloss: 0.0182679\tvalid_1's multi_logloss: 0.0612459\n",
      "[57]\ttraining's multi_logloss: 0.0169834\tvalid_1's multi_logloss: 0.0593784\n",
      "[58]\ttraining's multi_logloss: 0.0157734\tvalid_1's multi_logloss: 0.057479\n",
      "[59]\ttraining's multi_logloss: 0.0146499\tvalid_1's multi_logloss: 0.0559029\n",
      "[60]\ttraining's multi_logloss: 0.0136191\tvalid_1's multi_logloss: 0.0544967\n",
      "[61]\ttraining's multi_logloss: 0.0126731\tvalid_1's multi_logloss: 0.0528377\n",
      "[62]\ttraining's multi_logloss: 0.0117933\tvalid_1's multi_logloss: 0.0514192\n",
      "[63]\ttraining's multi_logloss: 0.0109739\tvalid_1's multi_logloss: 0.0502548\n",
      "[64]\ttraining's multi_logloss: 0.0102218\tvalid_1's multi_logloss: 0.0489597\n",
      "[65]\ttraining's multi_logloss: 0.00950987\tvalid_1's multi_logloss: 0.0475526\n",
      "[66]\ttraining's multi_logloss: 0.00884925\tvalid_1's multi_logloss: 0.0465241\n",
      "[67]\ttraining's multi_logloss: 0.00823773\tvalid_1's multi_logloss: 0.0457366\n",
      "[68]\ttraining's multi_logloss: 0.00766532\tvalid_1's multi_logloss: 0.0446711\n",
      "[69]\ttraining's multi_logloss: 0.00713555\tvalid_1's multi_logloss: 0.0440605\n",
      "[70]\ttraining's multi_logloss: 0.00664576\tvalid_1's multi_logloss: 0.0433335\n",
      "[71]\ttraining's multi_logloss: 0.00618801\tvalid_1's multi_logloss: 0.0426054\n",
      "[72]\ttraining's multi_logloss: 0.00576257\tvalid_1's multi_logloss: 0.0416403\n",
      "[73]\ttraining's multi_logloss: 0.00536187\tvalid_1's multi_logloss: 0.0411247\n",
      "[74]\ttraining's multi_logloss: 0.00499622\tvalid_1's multi_logloss: 0.0405587\n",
      "[75]\ttraining's multi_logloss: 0.00465733\tvalid_1's multi_logloss: 0.0401207\n",
      "[76]\ttraining's multi_logloss: 0.00433634\tvalid_1's multi_logloss: 0.0397757\n",
      "[77]\ttraining's multi_logloss: 0.0040435\tvalid_1's multi_logloss: 0.0392699\n",
      "[78]\ttraining's multi_logloss: 0.00376481\tvalid_1's multi_logloss: 0.0387628\n",
      "[79]\ttraining's multi_logloss: 0.00350045\tvalid_1's multi_logloss: 0.0382446\n",
      "[80]\ttraining's multi_logloss: 0.00326318\tvalid_1's multi_logloss: 0.0376272\n",
      "[81]\ttraining's multi_logloss: 0.00303715\tvalid_1's multi_logloss: 0.0371695\n",
      "[82]\ttraining's multi_logloss: 0.00283121\tvalid_1's multi_logloss: 0.0368504\n",
      "[83]\ttraining's multi_logloss: 0.00263625\tvalid_1's multi_logloss: 0.0363928\n",
      "[84]\ttraining's multi_logloss: 0.00245859\tvalid_1's multi_logloss: 0.0359845\n",
      "[85]\ttraining's multi_logloss: 0.00229551\tvalid_1's multi_logloss: 0.0356705\n",
      "[86]\ttraining's multi_logloss: 0.00213962\tvalid_1's multi_logloss: 0.0354216\n",
      "[87]\ttraining's multi_logloss: 0.00199611\tvalid_1's multi_logloss: 0.0349916\n",
      "[88]\ttraining's multi_logloss: 0.00186115\tvalid_1's multi_logloss: 0.0346298\n",
      "[89]\ttraining's multi_logloss: 0.00173677\tvalid_1's multi_logloss: 0.0342208\n",
      "[90]\ttraining's multi_logloss: 0.00162021\tvalid_1's multi_logloss: 0.0338087\n",
      "[91]\ttraining's multi_logloss: 0.00150932\tvalid_1's multi_logloss: 0.0336921\n",
      "[92]\ttraining's multi_logloss: 0.00140879\tvalid_1's multi_logloss: 0.0330017\n",
      "[93]\ttraining's multi_logloss: 0.00131584\tvalid_1's multi_logloss: 0.0327437\n",
      "[94]\ttraining's multi_logloss: 0.00122709\tvalid_1's multi_logloss: 0.0324265\n",
      "[95]\ttraining's multi_logloss: 0.00114592\tvalid_1's multi_logloss: 0.0321348\n",
      "[96]\ttraining's multi_logloss: 0.00106792\tvalid_1's multi_logloss: 0.0318176\n",
      "[97]\ttraining's multi_logloss: 0.000995954\tvalid_1's multi_logloss: 0.0315303\n",
      "[98]\ttraining's multi_logloss: 0.000929233\tvalid_1's multi_logloss: 0.0311196\n",
      "[99]\ttraining's multi_logloss: 0.000867268\tvalid_1's multi_logloss: 0.0309841\n",
      "[100]\ttraining's multi_logloss: 0.000810044\tvalid_1's multi_logloss: 0.0306699\n",
      "[101]\ttraining's multi_logloss: 0.00075776\tvalid_1's multi_logloss: 0.0303577\n",
      "[102]\ttraining's multi_logloss: 0.000706947\tvalid_1's multi_logloss: 0.0301178\n",
      "[103]\ttraining's multi_logloss: 0.000660357\tvalid_1's multi_logloss: 0.0301453\n",
      "[104]\ttraining's multi_logloss: 0.00061725\tvalid_1's multi_logloss: 0.0300492\n",
      "[105]\ttraining's multi_logloss: 0.00057719\tvalid_1's multi_logloss: 0.0299396\n",
      "[106]\ttraining's multi_logloss: 0.000539301\tvalid_1's multi_logloss: 0.0292435\n",
      "[107]\ttraining's multi_logloss: 0.000504329\tvalid_1's multi_logloss: 0.0289848\n",
      "[108]\ttraining's multi_logloss: 0.000470748\tvalid_1's multi_logloss: 0.0288751\n",
      "[109]\ttraining's multi_logloss: 0.000439643\tvalid_1's multi_logloss: 0.0286655\n",
      "[110]\ttraining's multi_logloss: 0.000411404\tvalid_1's multi_logloss: 0.028283\n",
      "[111]\ttraining's multi_logloss: 0.000384876\tvalid_1's multi_logloss: 0.0281336\n",
      "[112]\ttraining's multi_logloss: 0.000359432\tvalid_1's multi_logloss: 0.0276358\n",
      "[113]\ttraining's multi_logloss: 0.000336561\tvalid_1's multi_logloss: 0.027458\n",
      "[114]\ttraining's multi_logloss: 0.000315243\tvalid_1's multi_logloss: 0.0272819\n",
      "[115]\ttraining's multi_logloss: 0.000295153\tvalid_1's multi_logloss: 0.0275052\n",
      "[116]\ttraining's multi_logloss: 0.000276069\tvalid_1's multi_logloss: 0.0271407\n",
      "[117]\ttraining's multi_logloss: 0.000258655\tvalid_1's multi_logloss: 0.0269361\n",
      "[118]\ttraining's multi_logloss: 0.000241453\tvalid_1's multi_logloss: 0.0268777\n",
      "[119]\ttraining's multi_logloss: 0.000226064\tvalid_1's multi_logloss: 0.0266523\n",
      "[120]\ttraining's multi_logloss: 0.00021197\tvalid_1's multi_logloss: 0.0265815\n",
      "[121]\ttraining's multi_logloss: 0.000198073\tvalid_1's multi_logloss: 0.0263961\n",
      "[122]\ttraining's multi_logloss: 0.000185205\tvalid_1's multi_logloss: 0.0263109\n",
      "[123]\ttraining's multi_logloss: 0.000173573\tvalid_1's multi_logloss: 0.0261473\n",
      "[124]\ttraining's multi_logloss: 0.000162523\tvalid_1's multi_logloss: 0.0258739\n",
      "[125]\ttraining's multi_logloss: 0.000152415\tvalid_1's multi_logloss: 0.0256685\n",
      "[126]\ttraining's multi_logloss: 0.000142607\tvalid_1's multi_logloss: 0.0254554\n",
      "[127]\ttraining's multi_logloss: 0.000133415\tvalid_1's multi_logloss: 0.0254615\n",
      "[128]\ttraining's multi_logloss: 0.000125051\tvalid_1's multi_logloss: 0.0255155\n",
      "[129]\ttraining's multi_logloss: 0.000117006\tvalid_1's multi_logloss: 0.0252514\n",
      "[130]\ttraining's multi_logloss: 0.000109612\tvalid_1's multi_logloss: 0.0251278\n",
      "[131]\ttraining's multi_logloss: 0.000102572\tvalid_1's multi_logloss: 0.0250249\n",
      "[132]\ttraining's multi_logloss: 9.62318e-05\tvalid_1's multi_logloss: 0.0247071\n",
      "[133]\ttraining's multi_logloss: 9.03846e-05\tvalid_1's multi_logloss: 0.0244827\n",
      "[134]\ttraining's multi_logloss: 8.47436e-05\tvalid_1's multi_logloss: 0.0244042\n",
      "[135]\ttraining's multi_logloss: 7.94719e-05\tvalid_1's multi_logloss: 0.0243061\n",
      "[136]\ttraining's multi_logloss: 7.43425e-05\tvalid_1's multi_logloss: 0.0241027\n",
      "[137]\ttraining's multi_logloss: 6.97317e-05\tvalid_1's multi_logloss: 0.0239908\n",
      "[138]\ttraining's multi_logloss: 6.54165e-05\tvalid_1's multi_logloss: 0.0239378\n",
      "[139]\ttraining's multi_logloss: 6.15751e-05\tvalid_1's multi_logloss: 0.0238502\n",
      "[140]\ttraining's multi_logloss: 5.76345e-05\tvalid_1's multi_logloss: 0.0234592\n",
      "[141]\ttraining's multi_logloss: 5.4148e-05\tvalid_1's multi_logloss: 0.0230549\n",
      "[142]\ttraining's multi_logloss: 5.0786e-05\tvalid_1's multi_logloss: 0.0231077\n",
      "[143]\ttraining's multi_logloss: 4.76847e-05\tvalid_1's multi_logloss: 0.0228454\n",
      "[144]\ttraining's multi_logloss: 4.47258e-05\tvalid_1's multi_logloss: 0.0227095\n",
      "[145]\ttraining's multi_logloss: 4.20441e-05\tvalid_1's multi_logloss: 0.0225221\n",
      "[146]\ttraining's multi_logloss: 3.94033e-05\tvalid_1's multi_logloss: 0.0223273\n",
      "[147]\ttraining's multi_logloss: 3.71162e-05\tvalid_1's multi_logloss: 0.0220451\n",
      "[148]\ttraining's multi_logloss: 3.48988e-05\tvalid_1's multi_logloss: 0.021787\n",
      "[149]\ttraining's multi_logloss: 3.28151e-05\tvalid_1's multi_logloss: 0.0218873\n",
      "[150]\ttraining's multi_logloss: 3.0826e-05\tvalid_1's multi_logloss: 0.0218264\n",
      "[151]\ttraining's multi_logloss: 2.90844e-05\tvalid_1's multi_logloss: 0.0217132\n",
      "[152]\ttraining's multi_logloss: 2.73809e-05\tvalid_1's multi_logloss: 0.0215158\n",
      "[153]\ttraining's multi_logloss: 2.58314e-05\tvalid_1's multi_logloss: 0.0214197\n",
      "[154]\ttraining's multi_logloss: 2.43625e-05\tvalid_1's multi_logloss: 0.0216038\n",
      "[155]\ttraining's multi_logloss: 2.29879e-05\tvalid_1's multi_logloss: 0.021545\n",
      "[156]\ttraining's multi_logloss: 2.16924e-05\tvalid_1's multi_logloss: 0.0216619\n",
      "[157]\ttraining's multi_logloss: 2.04527e-05\tvalid_1's multi_logloss: 0.0218201\n",
      "[158]\ttraining's multi_logloss: 1.93111e-05\tvalid_1's multi_logloss: 0.0217591\n",
      "[159]\ttraining's multi_logloss: 1.82462e-05\tvalid_1's multi_logloss: 0.0218404\n",
      "[160]\ttraining's multi_logloss: 1.72425e-05\tvalid_1's multi_logloss: 0.0214392\n",
      "[161]\ttraining's multi_logloss: 1.63181e-05\tvalid_1's multi_logloss: 0.02141\n",
      "[162]\ttraining's multi_logloss: 1.53964e-05\tvalid_1's multi_logloss: 0.0212048\n",
      "[163]\ttraining's multi_logloss: 1.45671e-05\tvalid_1's multi_logloss: 0.0213256\n",
      "[164]\ttraining's multi_logloss: 1.38023e-05\tvalid_1's multi_logloss: 0.0211005\n",
      "[165]\ttraining's multi_logloss: 1.30533e-05\tvalid_1's multi_logloss: 0.021189\n",
      "[166]\ttraining's multi_logloss: 1.23368e-05\tvalid_1's multi_logloss: 0.0212698\n",
      "[167]\ttraining's multi_logloss: 1.16761e-05\tvalid_1's multi_logloss: 0.0210782\n",
      "[168]\ttraining's multi_logloss: 1.10654e-05\tvalid_1's multi_logloss: 0.020969\n",
      "[169]\ttraining's multi_logloss: 1.04809e-05\tvalid_1's multi_logloss: 0.0207001\n",
      "[170]\ttraining's multi_logloss: 9.93287e-06\tvalid_1's multi_logloss: 0.0205653\n",
      "[171]\ttraining's multi_logloss: 9.46341e-06\tvalid_1's multi_logloss: 0.0203008\n",
      "[172]\ttraining's multi_logloss: 8.99717e-06\tvalid_1's multi_logloss: 0.020164\n",
      "[173]\ttraining's multi_logloss: 8.55783e-06\tvalid_1's multi_logloss: 0.0201387\n",
      "[174]\ttraining's multi_logloss: 8.1648e-06\tvalid_1's multi_logloss: 0.0200805\n",
      "[175]\ttraining's multi_logloss: 7.785e-06\tvalid_1's multi_logloss: 0.0198746\n",
      "[176]\ttraining's multi_logloss: 7.43873e-06\tvalid_1's multi_logloss: 0.0197807\n",
      "[177]\ttraining's multi_logloss: 7.10902e-06\tvalid_1's multi_logloss: 0.01969\n",
      "[178]\ttraining's multi_logloss: 6.79885e-06\tvalid_1's multi_logloss: 0.0196096\n",
      "[179]\ttraining's multi_logloss: 6.50126e-06\tvalid_1's multi_logloss: 0.0195027\n",
      "[180]\ttraining's multi_logloss: 6.24431e-06\tvalid_1's multi_logloss: 0.0192628\n",
      "[181]\ttraining's multi_logloss: 5.99868e-06\tvalid_1's multi_logloss: 0.019458\n",
      "[182]\ttraining's multi_logloss: 5.7616e-06\tvalid_1's multi_logloss: 0.0195654\n",
      "[183]\ttraining's multi_logloss: 5.55003e-06\tvalid_1's multi_logloss: 0.0193047\n",
      "[184]\ttraining's multi_logloss: 5.33609e-06\tvalid_1's multi_logloss: 0.0192185\n",
      "[185]\ttraining's multi_logloss: 5.14846e-06\tvalid_1's multi_logloss: 0.0191277\n",
      "[186]\ttraining's multi_logloss: 4.95076e-06\tvalid_1's multi_logloss: 0.0192281\n",
      "[187]\ttraining's multi_logloss: 4.7633e-06\tvalid_1's multi_logloss: 0.0192727\n",
      "[188]\ttraining's multi_logloss: 4.59855e-06\tvalid_1's multi_logloss: 0.0194103\n",
      "[189]\ttraining's multi_logloss: 4.44177e-06\tvalid_1's multi_logloss: 0.019454\n",
      "[190]\ttraining's multi_logloss: 4.2977e-06\tvalid_1's multi_logloss: 0.019163\n",
      "[191]\ttraining's multi_logloss: 4.1647e-06\tvalid_1's multi_logloss: 0.0190473\n",
      "[192]\ttraining's multi_logloss: 4.02785e-06\tvalid_1's multi_logloss: 0.0190358\n",
      "[193]\ttraining's multi_logloss: 3.89585e-06\tvalid_1's multi_logloss: 0.0189581\n",
      "[194]\ttraining's multi_logloss: 3.774e-06\tvalid_1's multi_logloss: 0.0189784\n",
      "[195]\ttraining's multi_logloss: 3.66184e-06\tvalid_1's multi_logloss: 0.01893\n",
      "[196]\ttraining's multi_logloss: 3.5708e-06\tvalid_1's multi_logloss: 0.0188398\n",
      "[197]\ttraining's multi_logloss: 3.48248e-06\tvalid_1's multi_logloss: 0.0187511\n",
      "[198]\ttraining's multi_logloss: 3.39442e-06\tvalid_1's multi_logloss: 0.0187463\n",
      "[199]\ttraining's multi_logloss: 3.31327e-06\tvalid_1's multi_logloss: 0.0185287\n",
      "[200]\ttraining's multi_logloss: 3.22734e-06\tvalid_1's multi_logloss: 0.018431\n",
      "[201]\ttraining's multi_logloss: 3.15378e-06\tvalid_1's multi_logloss: 0.0183904\n",
      "[202]\ttraining's multi_logloss: 3.07823e-06\tvalid_1's multi_logloss: 0.0182732\n",
      "[203]\ttraining's multi_logloss: 3.00819e-06\tvalid_1's multi_logloss: 0.0181415\n",
      "[204]\ttraining's multi_logloss: 2.93787e-06\tvalid_1's multi_logloss: 0.0181138\n",
      "[205]\ttraining's multi_logloss: 2.8824e-06\tvalid_1's multi_logloss: 0.0179891\n",
      "[206]\ttraining's multi_logloss: 2.8213e-06\tvalid_1's multi_logloss: 0.0178313\n",
      "[207]\ttraining's multi_logloss: 2.76024e-06\tvalid_1's multi_logloss: 0.0177639\n",
      "[208]\ttraining's multi_logloss: 2.70799e-06\tvalid_1's multi_logloss: 0.0176944\n",
      "[209]\ttraining's multi_logloss: 2.6588e-06\tvalid_1's multi_logloss: 0.01762\n",
      "[210]\ttraining's multi_logloss: 2.60825e-06\tvalid_1's multi_logloss: 0.0175293\n",
      "[211]\ttraining's multi_logloss: 2.55726e-06\tvalid_1's multi_logloss: 0.0173565\n",
      "[212]\ttraining's multi_logloss: 2.51412e-06\tvalid_1's multi_logloss: 0.0172657\n",
      "[213]\ttraining's multi_logloss: 2.47171e-06\tvalid_1's multi_logloss: 0.0172243\n",
      "[214]\ttraining's multi_logloss: 2.42932e-06\tvalid_1's multi_logloss: 0.0171734\n",
      "[215]\ttraining's multi_logloss: 2.39011e-06\tvalid_1's multi_logloss: 0.0170923\n",
      "[216]\ttraining's multi_logloss: 2.35482e-06\tvalid_1's multi_logloss: 0.0170236\n",
      "[217]\ttraining's multi_logloss: 2.32071e-06\tvalid_1's multi_logloss: 0.0169873\n",
      "[218]\ttraining's multi_logloss: 2.28633e-06\tvalid_1's multi_logloss: 0.0168648\n",
      "[219]\ttraining's multi_logloss: 2.25025e-06\tvalid_1's multi_logloss: 0.0167958\n",
      "[220]\ttraining's multi_logloss: 2.21982e-06\tvalid_1's multi_logloss: 0.0167788\n",
      "[221]\ttraining's multi_logloss: 2.18857e-06\tvalid_1's multi_logloss: 0.0167783\n",
      "[222]\ttraining's multi_logloss: 2.15746e-06\tvalid_1's multi_logloss: 0.0168629\n",
      "[223]\ttraining's multi_logloss: 2.12608e-06\tvalid_1's multi_logloss: 0.0167677\n",
      "[224]\ttraining's multi_logloss: 2.09874e-06\tvalid_1's multi_logloss: 0.0166281\n",
      "[225]\ttraining's multi_logloss: 2.07006e-06\tvalid_1's multi_logloss: 0.01669\n",
      "[226]\ttraining's multi_logloss: 2.04525e-06\tvalid_1's multi_logloss: 0.0165865\n",
      "[227]\ttraining's multi_logloss: 2.0151e-06\tvalid_1's multi_logloss: 0.0166785\n",
      "[228]\ttraining's multi_logloss: 1.98851e-06\tvalid_1's multi_logloss: 0.016568\n",
      "[229]\ttraining's multi_logloss: 1.9629e-06\tvalid_1's multi_logloss: 0.0164836\n",
      "[230]\ttraining's multi_logloss: 1.93552e-06\tvalid_1's multi_logloss: 0.0164013\n",
      "[231]\ttraining's multi_logloss: 1.91707e-06\tvalid_1's multi_logloss: 0.0164879\n",
      "[232]\ttraining's multi_logloss: 1.89276e-06\tvalid_1's multi_logloss: 0.0164378\n",
      "[233]\ttraining's multi_logloss: 1.87288e-06\tvalid_1's multi_logloss: 0.0164813\n",
      "[234]\ttraining's multi_logloss: 1.84912e-06\tvalid_1's multi_logloss: 0.0165125\n",
      "[235]\ttraining's multi_logloss: 1.82851e-06\tvalid_1's multi_logloss: 0.0164841\n",
      "[236]\ttraining's multi_logloss: 1.80865e-06\tvalid_1's multi_logloss: 0.0165013\n",
      "[237]\ttraining's multi_logloss: 1.78821e-06\tvalid_1's multi_logloss: 0.0164989\n",
      "[238]\ttraining's multi_logloss: 1.7709e-06\tvalid_1's multi_logloss: 0.016559\n",
      "[239]\ttraining's multi_logloss: 1.75163e-06\tvalid_1's multi_logloss: 0.016553\n",
      "[240]\ttraining's multi_logloss: 1.73593e-06\tvalid_1's multi_logloss: 0.0165968\n",
      "[241]\ttraining's multi_logloss: 1.71964e-06\tvalid_1's multi_logloss: 0.0166396\n",
      "[242]\ttraining's multi_logloss: 1.70447e-06\tvalid_1's multi_logloss: 0.0165866\n",
      "[243]\ttraining's multi_logloss: 1.68626e-06\tvalid_1's multi_logloss: 0.016474\n",
      "[244]\ttraining's multi_logloss: 1.6729e-06\tvalid_1's multi_logloss: 0.0164782\n",
      "[245]\ttraining's multi_logloss: 1.65828e-06\tvalid_1's multi_logloss: 0.0164854\n",
      "[246]\ttraining's multi_logloss: 1.64189e-06\tvalid_1's multi_logloss: 0.0164128\n",
      "[247]\ttraining's multi_logloss: 1.62961e-06\tvalid_1's multi_logloss: 0.0164277\n",
      "[248]\ttraining's multi_logloss: 1.61488e-06\tvalid_1's multi_logloss: 0.0164622\n",
      "[249]\ttraining's multi_logloss: 1.60042e-06\tvalid_1's multi_logloss: 0.0164418\n",
      "[250]\ttraining's multi_logloss: 1.58696e-06\tvalid_1's multi_logloss: 0.0164809\n",
      "[251]\ttraining's multi_logloss: 1.57484e-06\tvalid_1's multi_logloss: 0.0164318\n",
      "[252]\ttraining's multi_logloss: 1.56271e-06\tvalid_1's multi_logloss: 0.0165077\n",
      "[253]\ttraining's multi_logloss: 1.5486e-06\tvalid_1's multi_logloss: 0.0164039\n",
      "[254]\ttraining's multi_logloss: 1.53415e-06\tvalid_1's multi_logloss: 0.0163257\n",
      "[255]\ttraining's multi_logloss: 1.52225e-06\tvalid_1's multi_logloss: 0.0163286\n",
      "[256]\ttraining's multi_logloss: 1.51089e-06\tvalid_1's multi_logloss: 0.016302\n",
      "[257]\ttraining's multi_logloss: 1.50043e-06\tvalid_1's multi_logloss: 0.0163551\n",
      "[258]\ttraining's multi_logloss: 1.4902e-06\tvalid_1's multi_logloss: 0.0163717\n",
      "[259]\ttraining's multi_logloss: 1.47855e-06\tvalid_1's multi_logloss: 0.0164303\n",
      "[260]\ttraining's multi_logloss: 1.46779e-06\tvalid_1's multi_logloss: 0.0164499\n",
      "[261]\ttraining's multi_logloss: 1.45596e-06\tvalid_1's multi_logloss: 0.0164794\n",
      "[262]\ttraining's multi_logloss: 1.44566e-06\tvalid_1's multi_logloss: 0.0164845\n",
      "[263]\ttraining's multi_logloss: 1.43574e-06\tvalid_1's multi_logloss: 0.0165524\n",
      "[264]\ttraining's multi_logloss: 1.42689e-06\tvalid_1's multi_logloss: 0.0166177\n",
      "[265]\ttraining's multi_logloss: 1.41769e-06\tvalid_1's multi_logloss: 0.016524\n",
      "[266]\ttraining's multi_logloss: 1.40799e-06\tvalid_1's multi_logloss: 0.0165408\n",
      "[267]\ttraining's multi_logloss: 1.3988e-06\tvalid_1's multi_logloss: 0.0164525\n",
      "[268]\ttraining's multi_logloss: 1.39032e-06\tvalid_1's multi_logloss: 0.0164257\n",
      "[269]\ttraining's multi_logloss: 1.38158e-06\tvalid_1's multi_logloss: 0.0164601\n",
      "[270]\ttraining's multi_logloss: 1.37173e-06\tvalid_1's multi_logloss: 0.0164372\n",
      "[271]\ttraining's multi_logloss: 1.36274e-06\tvalid_1's multi_logloss: 0.016355\n",
      "[272]\ttraining's multi_logloss: 1.35357e-06\tvalid_1's multi_logloss: 0.0163131\n",
      "[273]\ttraining's multi_logloss: 1.34531e-06\tvalid_1's multi_logloss: 0.0162861\n",
      "[274]\ttraining's multi_logloss: 1.33684e-06\tvalid_1's multi_logloss: 0.016242\n",
      "[275]\ttraining's multi_logloss: 1.32831e-06\tvalid_1's multi_logloss: 0.0162561\n",
      "[276]\ttraining's multi_logloss: 1.31983e-06\tvalid_1's multi_logloss: 0.0162662\n",
      "[277]\ttraining's multi_logloss: 1.31233e-06\tvalid_1's multi_logloss: 0.0162914\n",
      "[278]\ttraining's multi_logloss: 1.30451e-06\tvalid_1's multi_logloss: 0.0163077\n",
      "[279]\ttraining's multi_logloss: 1.29606e-06\tvalid_1's multi_logloss: 0.0163055\n",
      "[280]\ttraining's multi_logloss: 1.28875e-06\tvalid_1's multi_logloss: 0.0163505\n",
      "[281]\ttraining's multi_logloss: 1.2814e-06\tvalid_1's multi_logloss: 0.0162844\n",
      "[282]\ttraining's multi_logloss: 1.27422e-06\tvalid_1's multi_logloss: 0.0163131\n",
      "[283]\ttraining's multi_logloss: 1.26836e-06\tvalid_1's multi_logloss: 0.0163296\n",
      "[284]\ttraining's multi_logloss: 1.26067e-06\tvalid_1's multi_logloss: 0.0162782\n",
      "[285]\ttraining's multi_logloss: 1.2537e-06\tvalid_1's multi_logloss: 0.0162555\n",
      "[286]\ttraining's multi_logloss: 1.2458e-06\tvalid_1's multi_logloss: 0.0162817\n",
      "[287]\ttraining's multi_logloss: 1.24031e-06\tvalid_1's multi_logloss: 0.0163451\n",
      "[288]\ttraining's multi_logloss: 1.23423e-06\tvalid_1's multi_logloss: 0.0163298\n",
      "[289]\ttraining's multi_logloss: 1.22716e-06\tvalid_1's multi_logloss: 0.0162045\n",
      "[290]\ttraining's multi_logloss: 1.21936e-06\tvalid_1's multi_logloss: 0.0162366\n",
      "[291]\ttraining's multi_logloss: 1.21361e-06\tvalid_1's multi_logloss: 0.0162515\n",
      "[292]\ttraining's multi_logloss: 1.20767e-06\tvalid_1's multi_logloss: 0.0162901\n",
      "[293]\ttraining's multi_logloss: 1.2006e-06\tvalid_1's multi_logloss: 0.0162997\n",
      "[294]\ttraining's multi_logloss: 1.19431e-06\tvalid_1's multi_logloss: 0.0162879\n",
      "[295]\ttraining's multi_logloss: 1.18867e-06\tvalid_1's multi_logloss: 0.0163083\n",
      "[296]\ttraining's multi_logloss: 1.18251e-06\tvalid_1's multi_logloss: 0.0163391\n",
      "[297]\ttraining's multi_logloss: 1.17722e-06\tvalid_1's multi_logloss: 0.0163509\n",
      "[298]\ttraining's multi_logloss: 1.17135e-06\tvalid_1's multi_logloss: 0.0163815\n",
      "[299]\ttraining's multi_logloss: 1.16596e-06\tvalid_1's multi_logloss: 0.0163983\n",
      "[300]\ttraining's multi_logloss: 1.16076e-06\tvalid_1's multi_logloss: 0.0163605\n",
      "[301]\ttraining's multi_logloss: 1.15479e-06\tvalid_1's multi_logloss: 0.0163571\n",
      "[302]\ttraining's multi_logloss: 1.14921e-06\tvalid_1's multi_logloss: 0.0163897\n",
      "[303]\ttraining's multi_logloss: 1.14483e-06\tvalid_1's multi_logloss: 0.0163784\n",
      "[304]\ttraining's multi_logloss: 1.13968e-06\tvalid_1's multi_logloss: 0.0163593\n",
      "[305]\ttraining's multi_logloss: 1.1346e-06\tvalid_1's multi_logloss: 0.0163345\n",
      "[306]\ttraining's multi_logloss: 1.12949e-06\tvalid_1's multi_logloss: 0.0163498\n",
      "[307]\ttraining's multi_logloss: 1.1246e-06\tvalid_1's multi_logloss: 0.0163982\n",
      "[308]\ttraining's multi_logloss: 1.11967e-06\tvalid_1's multi_logloss: 0.0163617\n",
      "[309]\ttraining's multi_logloss: 1.11523e-06\tvalid_1's multi_logloss: 0.0164134\n",
      "[310]\ttraining's multi_logloss: 1.11001e-06\tvalid_1's multi_logloss: 0.0163881\n",
      "[311]\ttraining's multi_logloss: 1.10539e-06\tvalid_1's multi_logloss: 0.0164095\n",
      "[312]\ttraining's multi_logloss: 1.10043e-06\tvalid_1's multi_logloss: 0.0164018\n",
      "[313]\ttraining's multi_logloss: 1.0959e-06\tvalid_1's multi_logloss: 0.0164383\n",
      "[314]\ttraining's multi_logloss: 1.09131e-06\tvalid_1's multi_logloss: 0.0163716\n",
      "[315]\ttraining's multi_logloss: 1.08719e-06\tvalid_1's multi_logloss: 0.0163732\n",
      "[316]\ttraining's multi_logloss: 1.08291e-06\tvalid_1's multi_logloss: 0.0164106\n",
      "[317]\ttraining's multi_logloss: 1.07851e-06\tvalid_1's multi_logloss: 0.0163514\n",
      "[318]\ttraining's multi_logloss: 1.07501e-06\tvalid_1's multi_logloss: 0.0163636\n",
      "[319]\ttraining's multi_logloss: 1.07159e-06\tvalid_1's multi_logloss: 0.0163513\n",
      "[320]\ttraining's multi_logloss: 1.06806e-06\tvalid_1's multi_logloss: 0.0163789\n",
      "[321]\ttraining's multi_logloss: 1.06452e-06\tvalid_1's multi_logloss: 0.0163428\n",
      "[322]\ttraining's multi_logloss: 1.06122e-06\tvalid_1's multi_logloss: 0.0163922\n",
      "[323]\ttraining's multi_logloss: 1.05778e-06\tvalid_1's multi_logloss: 0.0164265\n",
      "[324]\ttraining's multi_logloss: 1.05431e-06\tvalid_1's multi_logloss: 0.0164658\n",
      "[325]\ttraining's multi_logloss: 1.0509e-06\tvalid_1's multi_logloss: 0.0164059\n",
      "[326]\ttraining's multi_logloss: 1.04769e-06\tvalid_1's multi_logloss: 0.0163903\n",
      "[327]\ttraining's multi_logloss: 1.04472e-06\tvalid_1's multi_logloss: 0.016384\n",
      "[328]\ttraining's multi_logloss: 1.0414e-06\tvalid_1's multi_logloss: 0.0164311\n",
      "[329]\ttraining's multi_logloss: 1.03825e-06\tvalid_1's multi_logloss: 0.0164431\n",
      "[330]\ttraining's multi_logloss: 1.03466e-06\tvalid_1's multi_logloss: 0.0164133\n",
      "[331]\ttraining's multi_logloss: 1.03183e-06\tvalid_1's multi_logloss: 0.0163749\n",
      "[332]\ttraining's multi_logloss: 1.02917e-06\tvalid_1's multi_logloss: 0.0163913\n",
      "[333]\ttraining's multi_logloss: 1.02664e-06\tvalid_1's multi_logloss: 0.0163904\n",
      "[334]\ttraining's multi_logloss: 1.02392e-06\tvalid_1's multi_logloss: 0.0163659\n",
      "[335]\ttraining's multi_logloss: 1.02136e-06\tvalid_1's multi_logloss: 0.0163719\n",
      "[336]\ttraining's multi_logloss: 1.01808e-06\tvalid_1's multi_logloss: 0.0163744\n",
      "[337]\ttraining's multi_logloss: 1.0155e-06\tvalid_1's multi_logloss: 0.0164122\n",
      "[338]\ttraining's multi_logloss: 1.01292e-06\tvalid_1's multi_logloss: 0.0164448\n",
      "[339]\ttraining's multi_logloss: 1.01052e-06\tvalid_1's multi_logloss: 0.0164958\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', header=None)\n",
    "column_names = [str(i) for i in range(X_test.shape[1])]\n",
    "\n",
    "X_train = pd.read_csv('./human_activity/train/X_train.txt',sep='\\s+', names=column_names )\n",
    "X_test = pd.read_csv('./human_activity/test/X_test.txt',sep='\\s+', names=column_names)\n",
    "y_train = pd.read_csv('./human_activity/train/y_train.txt',sep='\\s+', header=None, names=['action'])\n",
    "y_test = pd.read_csv('./human_activity/test/y_test.txt',sep='\\s+', header=None, names=['action'])\n",
    "\n",
    "y_test = y_test['action'] - 1\n",
    "y_train = y_train['action'] -1\n",
    "\n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "lgbm = LGBMClassifier(n_estimators=400, learning_rate=0.05, random_state=42)\n",
    "\n",
    "evals = [(X_tr, y_tr), (X_val, y_val)]\n",
    "lgbm.fit(X_tr, y_tr, early_stopping_rounds=50, eval_metric='logloss', eval_set=evals, verbose=True)\n",
    "\n",
    "preds =lgbm.predict(X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2624911-e924-4dc2-85c5-37485a9825de",
   "metadata": {},
   "source": [
    "# 산탄데르 고객 만족 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b9f6d-e3df-4af7-88bb-956fbdcb4180",
   "metadata": {},
   "source": [
    "## Hyperopt 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ed0751f8-54ec-4646-9c35-542f1eaefcd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset shape: (76020, 371)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.77</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "cust_df = pd.read_csv(\"./train_santander.csv\", encoding='latin-1')\n",
    "print('dataset shape:', cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1d5b09ab-07c4-4661-a0cb-7e33c153dd25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 76020 entries, 0 to 76019\n",
      "Columns: 371 entries, ID to TARGET\n",
      "dtypes: float64(111), int64(260)\n",
      "memory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "42c160cd-b123-4ba1-ab26-ae305210a2c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET\n",
       "0    73012\n",
       "1     3008\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= cust_df['TARGET']\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "83c7c40f-5ac9-461d-b78e-27c41b8878cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET\n",
      "0    0.960431\n",
      "1    0.039569\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Target값의 불균형이 심하다.\n",
    "print(y.value_counts()/len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "4af1ff11-73c4-46fa-9dda-cbed9f133a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_df['var3'].replace(-999999, 2, inplace=True)\n",
    "cust_df.drop('ID', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9861ce8e-3289-4d30-920a-5712cca7e58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TARGET\n",
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = cust_df.iloc[:,-1:]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f75d845-705e-424d-aacb-872a7b68a676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var3</th>\n",
       "      <th>var15</th>\n",
       "      <th>imp_ent_var16_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult1</th>\n",
       "      <th>imp_op_var39_comer_ult3</th>\n",
       "      <th>imp_op_var40_comer_ult1</th>\n",
       "      <th>imp_op_var40_comer_ult3</th>\n",
       "      <th>imp_op_var40_efect_ult1</th>\n",
       "      <th>imp_op_var40_efect_ult3</th>\n",
       "      <th>imp_op_var40_ult1</th>\n",
       "      <th>...</th>\n",
       "      <th>saldo_medio_var29_ult3</th>\n",
       "      <th>saldo_medio_var33_hace2</th>\n",
       "      <th>saldo_medio_var33_hace3</th>\n",
       "      <th>saldo_medio_var33_ult1</th>\n",
       "      <th>saldo_medio_var33_ult3</th>\n",
       "      <th>saldo_medio_var44_hace2</th>\n",
       "      <th>saldo_medio_var44_hace3</th>\n",
       "      <th>saldo_medio_var44_ult1</th>\n",
       "      <th>saldo_medio_var44_ult3</th>\n",
       "      <th>var38</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39205.170000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49278.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67333.770000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64007.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>117310.979016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 369 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                 0.0                      0.0   \n",
       "1     2     34                 0.0                      0.0   \n",
       "2     2     23                 0.0                      0.0   \n",
       "3     2     37                 0.0                    195.0   \n",
       "4     2     39                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "3                    195.0                      0.0                      0.0   \n",
       "4                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                      0.0                      0.0                0.0  ...   \n",
       "1                      0.0                      0.0                0.0  ...   \n",
       "2                      0.0                      0.0                0.0  ...   \n",
       "3                      0.0                      0.0                0.0  ...   \n",
       "4                      0.0                      0.0                0.0  ...   \n",
       "\n",
       "   saldo_medio_var29_ult3  saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "3                     0.0                      0.0                      0.0   \n",
       "4                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var33_ult1  saldo_medio_var33_ult3  saldo_medio_var44_hace2  \\\n",
       "0                     0.0                     0.0                      0.0   \n",
       "1                     0.0                     0.0                      0.0   \n",
       "2                     0.0                     0.0                      0.0   \n",
       "3                     0.0                     0.0                      0.0   \n",
       "4                     0.0                     0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_hace3  saldo_medio_var44_ult1  saldo_medio_var44_ult3  \\\n",
       "0                      0.0                     0.0                     0.0   \n",
       "1                      0.0                     0.0                     0.0   \n",
       "2                      0.0                     0.0                     0.0   \n",
       "3                      0.0                     0.0                     0.0   \n",
       "4                      0.0                     0.0                     0.0   \n",
       "\n",
       "           var38  \n",
       "0   39205.170000  \n",
       "1   49278.030000  \n",
       "2   67333.770000  \n",
       "3   64007.970000  \n",
       "4  117310.979016  \n",
       "\n",
       "[5 rows x 369 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cust_df.iloc[:,:-1]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "fbb645bc-f595-47e7-b57d-0c9cf7119cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2, random_state=0)\n",
    "\n",
    "# X_train, y_train을 다시 학습과 검증 데이터 세트로 분리. \n",
    "X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train,\n",
    "                                                    test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b972c-f9b2-48df-9488-569cfe87ee27",
   "metadata": {},
   "source": [
    "### XGBClassifier 모델 학습과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a931d5da-0fb7-47de-9d19-4da11a592002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83603\tvalidation_1-auc:0.80978\n",
      "[1]\tvalidation_0-auc:0.83783\tvalidation_1-auc:0.81126\n",
      "[2]\tvalidation_0-auc:0.83892\tvalidation_1-auc:0.81192\n",
      "[3]\tvalidation_0-auc:0.84090\tvalidation_1-auc:0.81349\n",
      "[4]\tvalidation_0-auc:0.84187\tvalidation_1-auc:0.81356\n",
      "[5]\tvalidation_0-auc:0.84355\tvalidation_1-auc:0.81422\n",
      "[6]\tvalidation_0-auc:0.84534\tvalidation_1-auc:0.81550\n",
      "[7]\tvalidation_0-auc:0.84658\tvalidation_1-auc:0.81623\n",
      "[8]\tvalidation_0-auc:0.84727\tvalidation_1-auc:0.81669\n",
      "[9]\tvalidation_0-auc:0.84794\tvalidation_1-auc:0.81668\n",
      "[10]\tvalidation_0-auc:0.84980\tvalidation_1-auc:0.81828\n",
      "[11]\tvalidation_0-auc:0.85105\tvalidation_1-auc:0.81965\n",
      "[12]\tvalidation_0-auc:0.85217\tvalidation_1-auc:0.81999\n",
      "[13]\tvalidation_0-auc:0.85301\tvalidation_1-auc:0.82049\n",
      "[14]\tvalidation_0-auc:0.85558\tvalidation_1-auc:0.82210\n",
      "[15]\tvalidation_0-auc:0.85662\tvalidation_1-auc:0.82288\n",
      "[16]\tvalidation_0-auc:0.85811\tvalidation_1-auc:0.82380\n",
      "[17]\tvalidation_0-auc:0.85864\tvalidation_1-auc:0.82365\n",
      "[18]\tvalidation_0-auc:0.85961\tvalidation_1-auc:0.82403\n",
      "[19]\tvalidation_0-auc:0.86068\tvalidation_1-auc:0.82511\n",
      "[20]\tvalidation_0-auc:0.86154\tvalidation_1-auc:0.82607\n",
      "[21]\tvalidation_0-auc:0.86216\tvalidation_1-auc:0.82672\n",
      "[22]\tvalidation_0-auc:0.86279\tvalidation_1-auc:0.82744\n",
      "[23]\tvalidation_0-auc:0.86336\tvalidation_1-auc:0.82820\n",
      "[24]\tvalidation_0-auc:0.86362\tvalidation_1-auc:0.82811\n",
      "[25]\tvalidation_0-auc:0.86400\tvalidation_1-auc:0.82848\n",
      "[26]\tvalidation_0-auc:0.86472\tvalidation_1-auc:0.82879\n",
      "[27]\tvalidation_0-auc:0.86532\tvalidation_1-auc:0.82927\n",
      "[28]\tvalidation_0-auc:0.86598\tvalidation_1-auc:0.82946\n",
      "[29]\tvalidation_0-auc:0.86666\tvalidation_1-auc:0.83019\n",
      "[30]\tvalidation_0-auc:0.86741\tvalidation_1-auc:0.83112\n",
      "[31]\tvalidation_0-auc:0.86805\tvalidation_1-auc:0.83138\n",
      "[32]\tvalidation_0-auc:0.86854\tvalidation_1-auc:0.83139\n",
      "[33]\tvalidation_0-auc:0.86912\tvalidation_1-auc:0.83163\n",
      "[34]\tvalidation_0-auc:0.86962\tvalidation_1-auc:0.83172\n",
      "[35]\tvalidation_0-auc:0.87017\tvalidation_1-auc:0.83175\n",
      "[36]\tvalidation_0-auc:0.87049\tvalidation_1-auc:0.83170\n",
      "[37]\tvalidation_0-auc:0.87123\tvalidation_1-auc:0.83140\n",
      "[38]\tvalidation_0-auc:0.87213\tvalidation_1-auc:0.83194\n",
      "[39]\tvalidation_0-auc:0.87246\tvalidation_1-auc:0.83175\n",
      "[40]\tvalidation_0-auc:0.87333\tvalidation_1-auc:0.83193\n",
      "[41]\tvalidation_0-auc:0.87420\tvalidation_1-auc:0.83173\n",
      "[42]\tvalidation_0-auc:0.87491\tvalidation_1-auc:0.83183\n",
      "[43]\tvalidation_0-auc:0.87562\tvalidation_1-auc:0.83177\n",
      "[44]\tvalidation_0-auc:0.87626\tvalidation_1-auc:0.83167\n",
      "[45]\tvalidation_0-auc:0.87685\tvalidation_1-auc:0.83159\n",
      "[46]\tvalidation_0-auc:0.87738\tvalidation_1-auc:0.83169\n",
      "[47]\tvalidation_0-auc:0.87786\tvalidation_1-auc:0.83171\n",
      "[48]\tvalidation_0-auc:0.87836\tvalidation_1-auc:0.83191\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=156, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=156, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.05, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=100, n_jobs=None,\n",
       "              num_parallel_tree=None, random_state=156, ...)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# n_estimators는 100으로, learning_rate 0.05, random state는 예제 수행 시마다 동일 예측 결과를 위해 설정. \n",
    "xgb_clf = XGBClassifier(n_estimators=100, learning_rate=0.05, random_state=156)\n",
    "\n",
    "# 성능 평가 지표를 auc로, 조기 중단 파라미터는 10으로 설정하고 학습 수행. \n",
    "xgb_clf.fit(X_tr, y_tr, early_stopping_rounds=10, eval_metric='auc', eval_set=[(X_tr, y_tr), (X_val, y_val)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8d5b4bc-3d24-4c77-b466-0330bfc1e671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.8383\n"
     ]
    }
   ],
   "source": [
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1])\n",
    "print('ROC AUC: {0:.4f}'.format(xgb_roc_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7739de4-b895-4bb2-b9a2-1606fc3a408e",
   "metadata": {},
   "source": [
    "### Hyperopt 적용해서 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "931408c1-b634-4cc8-b3ac-93db7b9bede2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "\n",
    "# max_depth는 5에서 15까지 1간격으로, min_child_weight는 1에서 6까지 1간격으로\n",
    "# colsample_bytree는 0.5에서 0.95사이, learning_rate는 0.01에서 0.2사이 정규 분포된 값으로 검색. \n",
    "\n",
    "xgb_search_space = {'max_depth': hp.quniform('max_depth', 5, 15, 1),\n",
    "                    'n_estimators': hp.quniform('n_estimators', 20, 60, 10),\n",
    "                    'min_child_weight': hp.quniform('min_child_weight', 1, 5, 1),\n",
    "                    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                    'learning_rate': hp.quniform('learning_rate', 0.1, 0.2, 0.05)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60a1c7b9-a6d5-4808-8c52-3865390bd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# 목적 함수 설정. \n",
    "# 추후 fmin()에서 입력된 search_space값으로 XGBClassifier 교차 검증 학습 후 -1* roc_auc 평균 값을 반환.  \n",
    "def objective_func(search_space):\n",
    "    xgb_clf = XGBClassifier(n_estimators=int(search_space['n_estimators']), \n",
    "                            max_depth=int(search_space['max_depth']),\n",
    "                            min_child_weight=int(search_space['min_child_weight']),\n",
    "                            colsample_bytree=search_space['colsample_bytree'],\n",
    "                            learning_rate=search_space['learning_rate'],\n",
    "                            eval_metric='auc'\n",
    "                           )\n",
    "\n",
    "    xgb_clf.fit(X_tr,y_tr)\n",
    "    \n",
    "    auc_accuracy = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "    return -1*auc_accuracy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "40ec1a75-6007-4bb5-8760-e3a7456fbe2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████| 50/50 [00:56<00:00,  1.14s/trial, best loss: -0.8476621076539018]\n",
      "best: {'colsample_bytree': 0.6777376334513477, 'learning_rate': 0.1, 'max_depth': 6.0, 'min_child_weight': 2.0, 'n_estimators': 60.0}\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출.\n",
    "best = fmin(fn=objective_func,\n",
    "            space=xgb_search_space,\n",
    "            algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, \n",
    "            rstate=np.random.default_rng(seed=0))\n",
    "\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c934254f-1e49-421d-85fa-30dd62672e23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8476621076539018"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators=60, \n",
    "                        max_depth=6,\n",
    "                        min_child_weight=2,\n",
    "                        colsample_bytree=0.6777376334513477,\n",
    "                        learning_rate=0.1,\n",
    "                        eval_matric='auc'\n",
    "                       )\n",
    "\n",
    "xgb_clf.fit(X_tr,y_tr)\n",
    "\n",
    "auc_accuracy = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:,1])\n",
    "auc_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94255dc7-f56a-45fb-bf53-c45ebcbeea31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
